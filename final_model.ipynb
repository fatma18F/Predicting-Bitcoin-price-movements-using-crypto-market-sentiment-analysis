{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fe9ab4",
   "metadata": {
    "id": "07fe9ab4"
   },
   "outputs": [],
   "source": [
    "# Necessary dependency for the Bertweet preprocessor to encode emojis\n",
    "# !pip3 install emoji\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import TFAutoModel, BertTokenizerFast, AutoTokenizer\n",
    "from datetime import datetime, timedelta\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "tweets_file_path = \"drive/MyDrive/fatma-nlp/tweets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae5ef43",
   "metadata": {
    "id": "cae5ef43"
   },
   "source": [
    "# 0. Candidate language models to use for tweet sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d411f966",
   "metadata": {
    "id": "d411f966"
   },
   "outputs": [],
   "source": [
    "# https://github.com/cardiffnlp/tweeteval\n",
    "\n",
    "# Candidate models to use:\n",
    "# Have a look at VADER (Valence Aware dictionnary and sEntiment Reasoner)\n",
    "    # Rule-based sentiment analysis. Specifically suited for social media text\n",
    "# TODO: Have a look at https://huggingface.co/docs/transformers/model_doc/bertweet\n",
    "# TODO: Check this one: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment\n",
    "    # General tweet (not specifically crypto/ btc related) sentiments\n",
    "\n",
    "# For our project, we decided to work with Bertweet\n",
    "model_name = 'vinai/bertweet-base'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e922a",
   "metadata": {
    "id": "4b5e922a"
   },
   "source": [
    "# 1. Load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88c57a01",
   "metadata": {
    "id": "88c57a01"
   },
   "outputs": [],
   "source": [
    "def load_tweets_from_file(filename):\n",
    "    with open(filename, \"r\", encoding='utf-8') as file:\n",
    "        json_object = json.load(file)\n",
    "    return json_object[\"tweets\"]\n",
    "\n",
    "json_object = load_tweets_from_file(tweets_file_path)\n",
    "df = pd.json_normalize(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a8e090c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "5a8e090c",
    "outputId": "3c148519-4840-4165-febf-73d98a4ae3a6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Word Cloud\n",
    "text = df['content'].values\n",
    "wordcloud = WordCloud().generate(str(text))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f81a40bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "id": "f81a40bc",
    "outputId": "f38b2d83-64cf-4205-a88c-de7bd4d638e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      " content           object\n",
      "replyCount         int64\n",
      "retweetCount       int64\n",
      "likeCount          int64\n",
      "quoteCount         int64\n",
      "lang              object\n",
      "verified            bool\n",
      "followersCount     int64\n",
      "friendsCount       int64\n",
      "statusesCount      int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1c54f406-fd0d-4bce-813a-5dd6dccaa2d2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>lang</th>\n",
       "      <th>verified</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>statusesCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00+00:00</th>\n",
       "      <td>$btc continues to bounce off the ytd anchored ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>203116</td>\n",
       "      <td>1400</td>\n",
       "      <td>53551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00+00:00</th>\n",
       "      <td>current price of bitcoin: $46320 (-1.85%) $btc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>67</td>\n",
       "      <td>65</td>\n",
       "      <td>1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:02+00:00</th>\n",
       "      <td>most people underestimate the impact #bitcoin ...</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>211</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>245622</td>\n",
       "      <td>750</td>\n",
       "      <td>18051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:02+00:00</th>\n",
       "      <td>bitcoin - btc price: $46,306.45 change in 1h: ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>4609</td>\n",
       "      <td>0</td>\n",
       "      <td>380423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:02+00:00</th>\n",
       "      <td>#bitcoin is currently $46,230.6131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>7023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-30 23:59:00+00:00</th>\n",
       "      <td>candle of day 30/01/2022 closed. open: $ 38,20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-30 23:59:06+00:00</th>\n",
       "      <td>#bitcoin is trying to get over $38.5k here. be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-30 23:59:09+00:00</th>\n",
       "      <td>buy more #bitcoin ser</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>865</td>\n",
       "      <td>1688</td>\n",
       "      <td>7818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-30 23:59:23+00:00</th>\n",
       "      <td>we are 3 months in the bear market. your welco...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-30 23:59:34+00:00</th>\n",
       "      <td>the next few days will be very pivotal for #bi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>73</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321397 rows  10 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c54f406-fd0d-4bce-813a-5dd6dccaa2d2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1c54f406-fd0d-4bce-813a-5dd6dccaa2d2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1c54f406-fd0d-4bce-813a-5dd6dccaa2d2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                                     content  \\\n",
       "date                                                                           \n",
       "2022-01-01 00:00:00+00:00  $btc continues to bounce off the ytd anchored ...   \n",
       "2022-01-01 00:00:00+00:00  current price of bitcoin: $46320 (-1.85%) $btc...   \n",
       "2022-01-01 00:00:02+00:00  most people underestimate the impact #bitcoin ...   \n",
       "2022-01-01 00:00:02+00:00  bitcoin - btc price: $46,306.45 change in 1h: ...   \n",
       "2022-01-01 00:00:02+00:00                 #bitcoin is currently $46,230.6131   \n",
       "...                                                                      ...   \n",
       "2022-01-30 23:59:00+00:00  candle of day 30/01/2022 closed. open: $ 38,20...   \n",
       "2022-01-30 23:59:06+00:00  #bitcoin is trying to get over $38.5k here. be...   \n",
       "2022-01-30 23:59:09+00:00                              buy more #bitcoin ser   \n",
       "2022-01-30 23:59:23+00:00  we are 3 months in the bear market. your welco...   \n",
       "2022-01-30 23:59:34+00:00  the next few days will be very pivotal for #bi...   \n",
       "\n",
       "                           replyCount  retweetCount  likeCount  quoteCount  \\\n",
       "date                                                                         \n",
       "2022-01-01 00:00:00+00:00           0             0         20           0   \n",
       "2022-01-01 00:00:00+00:00           0             0          0           0   \n",
       "2022-01-01 00:00:02+00:00          20            31        211           3   \n",
       "2022-01-01 00:00:02+00:00           0             0          0           0   \n",
       "2022-01-01 00:00:02+00:00           0             0          0           0   \n",
       "...                               ...           ...        ...         ...   \n",
       "2022-01-30 23:59:00+00:00           0             0          0           0   \n",
       "2022-01-30 23:59:06+00:00           0             0          1           0   \n",
       "2022-01-30 23:59:09+00:00           0             0          1           0   \n",
       "2022-01-30 23:59:23+00:00           1             0          2           0   \n",
       "2022-01-30 23:59:34+00:00           1             0          0           0   \n",
       "\n",
       "                          lang  verified  followersCount  friendsCount  \\\n",
       "date                                                                     \n",
       "2022-01-01 00:00:00+00:00   en      True          203116          1400   \n",
       "2022-01-01 00:00:00+00:00   en     False              67            65   \n",
       "2022-01-01 00:00:02+00:00   en      True          245622           750   \n",
       "2022-01-01 00:00:02+00:00   en     False            4609             0   \n",
       "2022-01-01 00:00:02+00:00   en     False              24             0   \n",
       "...                        ...       ...             ...           ...   \n",
       "2022-01-30 23:59:00+00:00   en     False              35             5   \n",
       "2022-01-30 23:59:06+00:00   en     False              13             4   \n",
       "2022-01-30 23:59:09+00:00   en     False             865          1688   \n",
       "2022-01-30 23:59:23+00:00   en     False               5            12   \n",
       "2022-01-30 23:59:34+00:00   en     False              28            73   \n",
       "\n",
       "                           statusesCount  \n",
       "date                                      \n",
       "2022-01-01 00:00:00+00:00          53551  \n",
       "2022-01-01 00:00:00+00:00           1759  \n",
       "2022-01-01 00:00:02+00:00          18051  \n",
       "2022-01-01 00:00:02+00:00         380423  \n",
       "2022-01-01 00:00:02+00:00           7023  \n",
       "...                                  ...  \n",
       "2022-01-30 23:59:00+00:00            407  \n",
       "2022-01-30 23:59:06+00:00            189  \n",
       "2022-01-30 23:59:09+00:00           7818  \n",
       "2022-01-30 23:59:23+00:00            211  \n",
       "2022-01-30 23:59:34+00:00            143  \n",
       "\n",
       "[321397 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index the dataframe by date to allow slicing by datetimes\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('date')\n",
    "print(\"Data types:\\n\", df.dtypes)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d42f888f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "d42f888f",
    "outputId": "299598cd-4af5-4317-a995-fce1742e0a3c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4dc100b0-13b3-423f-afa4-b18a3dd7923b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>lang</th>\n",
       "      <th>verified</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>statusesCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00+00:00</th>\n",
       "      <td>$btc continues to bounce off the ytd anchored ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>203116</td>\n",
       "      <td>1400</td>\n",
       "      <td>53551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00+00:00</th>\n",
       "      <td>current price of bitcoin: $46320 (-1.85%) $btc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>67</td>\n",
       "      <td>65</td>\n",
       "      <td>1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:02+00:00</th>\n",
       "      <td>most people underestimate the impact #bitcoin ...</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>211</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>245622</td>\n",
       "      <td>750</td>\n",
       "      <td>18051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:02+00:00</th>\n",
       "      <td>bitcoin - btc price: $46,306.45 change in 1h: ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>4609</td>\n",
       "      <td>0</td>\n",
       "      <td>380423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:02+00:00</th>\n",
       "      <td>#bitcoin is currently $46,230.6131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>7023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:59:06+00:00</th>\n",
       "      <td>my biggest qualm about #bitcoin is not whether...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:59:21+00:00</th>\n",
       "      <td>time for the god #bitcoin candles</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>2401</td>\n",
       "      <td>244</td>\n",
       "      <td>3077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:59:39+00:00</th>\n",
       "      <td>1 bitcoin ( #btc ) dollar: 46,649.32$ 1 bitcoi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>5746</td>\n",
       "      <td>4</td>\n",
       "      <td>19822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:59:41+00:00</th>\n",
       "      <td>i'm done selling everyone! i'm fucking done wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>92</td>\n",
       "      <td>1337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00+00:00</th>\n",
       "      <td>today's cryptocurrency fear and greed index: 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>840</td>\n",
       "      <td>1</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows  10 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4dc100b0-13b3-423f-afa4-b18a3dd7923b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4dc100b0-13b3-423f-afa4-b18a3dd7923b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4dc100b0-13b3-423f-afa4-b18a3dd7923b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                                     content  \\\n",
       "date                                                                           \n",
       "2022-01-01 00:00:00+00:00  $btc continues to bounce off the ytd anchored ...   \n",
       "2022-01-01 00:00:00+00:00  current price of bitcoin: $46320 (-1.85%) $btc...   \n",
       "2022-01-01 00:00:02+00:00  most people underestimate the impact #bitcoin ...   \n",
       "2022-01-01 00:00:02+00:00  bitcoin - btc price: $46,306.45 change in 1h: ...   \n",
       "2022-01-01 00:00:02+00:00                 #bitcoin is currently $46,230.6131   \n",
       "...                                                                      ...   \n",
       "2022-01-01 00:59:06+00:00  my biggest qualm about #bitcoin is not whether...   \n",
       "2022-01-01 00:59:21+00:00                  time for the god #bitcoin candles   \n",
       "2022-01-01 00:59:39+00:00  1 bitcoin ( #btc ) dollar: 46,649.32$ 1 bitcoi...   \n",
       "2022-01-01 00:59:41+00:00  i'm done selling everyone! i'm fucking done wi...   \n",
       "2022-01-01 01:00:00+00:00  today's cryptocurrency fear and greed index: 2...   \n",
       "\n",
       "                           replyCount  retweetCount  likeCount  quoteCount  \\\n",
       "date                                                                         \n",
       "2022-01-01 00:00:00+00:00           0             0         20           0   \n",
       "2022-01-01 00:00:00+00:00           0             0          0           0   \n",
       "2022-01-01 00:00:02+00:00          20            31        211           3   \n",
       "2022-01-01 00:00:02+00:00           0             0          0           0   \n",
       "2022-01-01 00:00:02+00:00           0             0          0           0   \n",
       "...                               ...           ...        ...         ...   \n",
       "2022-01-01 00:59:06+00:00           0             0          0           0   \n",
       "2022-01-01 00:59:21+00:00           0             0          1           0   \n",
       "2022-01-01 00:59:39+00:00           1             1          0           0   \n",
       "2022-01-01 00:59:41+00:00           0             0          0           0   \n",
       "2022-01-01 01:00:00+00:00           1             1          2           0   \n",
       "\n",
       "                          lang  verified  followersCount  friendsCount  \\\n",
       "date                                                                     \n",
       "2022-01-01 00:00:00+00:00   en      True          203116          1400   \n",
       "2022-01-01 00:00:00+00:00   en     False              67            65   \n",
       "2022-01-01 00:00:02+00:00   en      True          245622           750   \n",
       "2022-01-01 00:00:02+00:00   en     False            4609             0   \n",
       "2022-01-01 00:00:02+00:00   en     False              24             0   \n",
       "...                        ...       ...             ...           ...   \n",
       "2022-01-01 00:59:06+00:00   en     False               5            48   \n",
       "2022-01-01 00:59:21+00:00   en     False            2401           244   \n",
       "2022-01-01 00:59:39+00:00   en     False            5746             4   \n",
       "2022-01-01 00:59:41+00:00   en     False              26            92   \n",
       "2022-01-01 01:00:00+00:00   en     False             840             1   \n",
       "\n",
       "                           statusesCount  \n",
       "date                                      \n",
       "2022-01-01 00:00:00+00:00          53551  \n",
       "2022-01-01 00:00:00+00:00           1759  \n",
       "2022-01-01 00:00:02+00:00          18051  \n",
       "2022-01-01 00:00:02+00:00         380423  \n",
       "2022-01-01 00:00:02+00:00           7023  \n",
       "...                                  ...  \n",
       "2022-01-01 00:59:06+00:00             70  \n",
       "2022-01-01 00:59:21+00:00           3077  \n",
       "2022-01-01 00:59:39+00:00          19822  \n",
       "2022-01-01 00:59:41+00:00           1337  \n",
       "2022-01-01 01:00:00+00:00            555  \n",
       "\n",
       "[356 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore some tweets sliced by datetimes\n",
    "df.loc['2022-01-01 00:00:00':'2022-01-01 01:00:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088fd56",
   "metadata": {
    "id": "a088fd56"
   },
   "source": [
    "# 2. Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35be86f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "35be86f3",
    "outputId": "416422c2-6fad-4bd3-c202-f769f5bdfce8",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f5147467-15a7-4e4b-8b21-a896e5df1d30\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>verified</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>statusesCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00+00:00</th>\n",
       "      <td>$btc continues to bounce off the ytd anchored ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>203116</td>\n",
       "      <td>1400</td>\n",
       "      <td>53551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:02+00:00</th>\n",
       "      <td>most people underestimate the impact #bitcoin ...</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>211</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>245622</td>\n",
       "      <td>750</td>\n",
       "      <td>18051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:03+00:00</th>\n",
       "      <td>bitcoin faces a year-end technical test after ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1824</td>\n",
       "      <td>171</td>\n",
       "      <td>10524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:06+00:00</th>\n",
       "      <td>crypto in 2021: a year in review (part 4) #bit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>6994</td>\n",
       "      <td>606</td>\n",
       "      <td>77904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:38+00:00</th>\n",
       "      <td>pump it #bitcoin</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>411</td>\n",
       "      <td>466</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-30 23:56:31+00:00</th>\n",
       "      <td>5 min left to go to close the week into the gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1457</td>\n",
       "      <td>4980</td>\n",
       "      <td>11432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-30 23:56:53+00:00</th>\n",
       "      <td>#bitcoin white house executive order. probably...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>85</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-30 23:59:06+00:00</th>\n",
       "      <td>#bitcoin is trying to get over $38.5k here. be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-30 23:59:09+00:00</th>\n",
       "      <td>buy more #bitcoin ser</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>865</td>\n",
       "      <td>1688</td>\n",
       "      <td>7818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-30 23:59:23+00:00</th>\n",
       "      <td>we are 3 months in the bear market. your welco...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148943 rows  9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5147467-15a7-4e4b-8b21-a896e5df1d30')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f5147467-15a7-4e4b-8b21-a896e5df1d30 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f5147467-15a7-4e4b-8b21-a896e5df1d30');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                                     content  \\\n",
       "date                                                                           \n",
       "2022-01-01 00:00:00+00:00  $btc continues to bounce off the ytd anchored ...   \n",
       "2022-01-01 00:00:02+00:00  most people underestimate the impact #bitcoin ...   \n",
       "2022-01-01 00:00:03+00:00  bitcoin faces a year-end technical test after ...   \n",
       "2022-01-01 00:00:06+00:00  crypto in 2021: a year in review (part 4) #bit...   \n",
       "2022-01-01 00:00:38+00:00                                   pump it #bitcoin   \n",
       "...                                                                      ...   \n",
       "2022-01-30 23:56:31+00:00  5 min left to go to close the week into the gr...   \n",
       "2022-01-30 23:56:53+00:00  #bitcoin white house executive order. probably...   \n",
       "2022-01-30 23:59:06+00:00  #bitcoin is trying to get over $38.5k here. be...   \n",
       "2022-01-30 23:59:09+00:00                              buy more #bitcoin ser   \n",
       "2022-01-30 23:59:23+00:00  we are 3 months in the bear market. your welco...   \n",
       "\n",
       "                           replyCount  retweetCount  likeCount  quoteCount  \\\n",
       "date                                                                         \n",
       "2022-01-01 00:00:00+00:00           0             0         20           0   \n",
       "2022-01-01 00:00:02+00:00          20            31        211           3   \n",
       "2022-01-01 00:00:03+00:00           0             4          4           0   \n",
       "2022-01-01 00:00:06+00:00           0             0          1           0   \n",
       "2022-01-01 00:00:38+00:00           0             1          1           0   \n",
       "...                               ...           ...        ...         ...   \n",
       "2022-01-30 23:56:31+00:00           0             0          1           0   \n",
       "2022-01-30 23:56:53+00:00           0             0          1           0   \n",
       "2022-01-30 23:59:06+00:00           0             0          1           0   \n",
       "2022-01-30 23:59:09+00:00           0             0          1           0   \n",
       "2022-01-30 23:59:23+00:00           1             0          2           0   \n",
       "\n",
       "                           verified  followersCount  friendsCount  \\\n",
       "date                                                                \n",
       "2022-01-01 00:00:00+00:00      True          203116          1400   \n",
       "2022-01-01 00:00:02+00:00      True          245622           750   \n",
       "2022-01-01 00:00:03+00:00     False            1824           171   \n",
       "2022-01-01 00:00:06+00:00     False            6994           606   \n",
       "2022-01-01 00:00:38+00:00     False             411           466   \n",
       "...                             ...             ...           ...   \n",
       "2022-01-30 23:56:31+00:00     False            1457          4980   \n",
       "2022-01-30 23:56:53+00:00     False              26            85   \n",
       "2022-01-30 23:59:06+00:00     False              13             4   \n",
       "2022-01-30 23:59:09+00:00     False             865          1688   \n",
       "2022-01-30 23:59:23+00:00     False               5            12   \n",
       "\n",
       "                           statusesCount  \n",
       "date                                      \n",
       "2022-01-01 00:00:00+00:00          53551  \n",
       "2022-01-01 00:00:02+00:00          18051  \n",
       "2022-01-01 00:00:03+00:00          10524  \n",
       "2022-01-01 00:00:06+00:00          77904  \n",
       "2022-01-01 00:00:38+00:00           2049  \n",
       "...                                  ...  \n",
       "2022-01-30 23:56:31+00:00          11432  \n",
       "2022-01-30 23:56:53+00:00            909  \n",
       "2022-01-30 23:59:06+00:00            189  \n",
       "2022-01-30 23:59:09+00:00           7818  \n",
       "2022-01-30 23:59:23+00:00            211  \n",
       "\n",
       "[148943 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.likeCount != 0]\n",
    "df = df[df.followersCount != 0]\n",
    "df = df.drop(columns=[\"lang\"], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980aae73",
   "metadata": {
    "id": "980aae73"
   },
   "source": [
    "# 3. Prepare the data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8732bfc",
   "metadata": {
    "id": "b8732bfc"
   },
   "source": [
    "### Slice tweets according to time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa19736c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "fa19736c",
    "outputId": "ac8be0eb-2344-4d29-83b5-7acf675c13a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "719\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(132, 9)\n",
      "(93, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cf9d6161-133a-4e6b-88af-42c9f6edb709\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>verified</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>statusesCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00+00:00</th>\n",
       "      <td>$btc continues to bounce off the ytd anchored ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>203116</td>\n",
       "      <td>1400</td>\n",
       "      <td>53551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:02+00:00</th>\n",
       "      <td>most people underestimate the impact #bitcoin ...</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>211</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>245622</td>\n",
       "      <td>750</td>\n",
       "      <td>18051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:03+00:00</th>\n",
       "      <td>bitcoin faces a year-end technical test after ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1824</td>\n",
       "      <td>171</td>\n",
       "      <td>10524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:06+00:00</th>\n",
       "      <td>crypto in 2021: a year in review (part 4) #bit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>6994</td>\n",
       "      <td>606</td>\n",
       "      <td>77904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:38+00:00</th>\n",
       "      <td>pump it #bitcoin</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>411</td>\n",
       "      <td>466</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:57:11+00:00</th>\n",
       "      <td>#bitcoin at $100000!!! oh wait.....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>534</td>\n",
       "      <td>1546</td>\n",
       "      <td>26283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:57:39+00:00</th>\n",
       "      <td>i'm glad #bitcoin gives you something to twee...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1042</td>\n",
       "      <td>1860</td>\n",
       "      <td>10047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:57:46+00:00</th>\n",
       "      <td>did you know that $5,000 get you over $50,000 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>555</td>\n",
       "      <td>459</td>\n",
       "      <td>3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:59:21+00:00</th>\n",
       "      <td>time for the god #bitcoin candles</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2401</td>\n",
       "      <td>244</td>\n",
       "      <td>3077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00+00:00</th>\n",
       "      <td>today's cryptocurrency fear and greed index: 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>840</td>\n",
       "      <td>1</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows  9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf9d6161-133a-4e6b-88af-42c9f6edb709')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-cf9d6161-133a-4e6b-88af-42c9f6edb709 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-cf9d6161-133a-4e6b-88af-42c9f6edb709');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                                     content  \\\n",
       "date                                                                           \n",
       "2022-01-01 00:00:00+00:00  $btc continues to bounce off the ytd anchored ...   \n",
       "2022-01-01 00:00:02+00:00  most people underestimate the impact #bitcoin ...   \n",
       "2022-01-01 00:00:03+00:00  bitcoin faces a year-end technical test after ...   \n",
       "2022-01-01 00:00:06+00:00  crypto in 2021: a year in review (part 4) #bit...   \n",
       "2022-01-01 00:00:38+00:00                                   pump it #bitcoin   \n",
       "...                                                                      ...   \n",
       "2022-01-01 00:57:11+00:00                #bitcoin at $100000!!! oh wait.....   \n",
       "2022-01-01 00:57:39+00:00   i'm glad #bitcoin gives you something to twee...   \n",
       "2022-01-01 00:57:46+00:00  did you know that $5,000 get you over $50,000 ...   \n",
       "2022-01-01 00:59:21+00:00                  time for the god #bitcoin candles   \n",
       "2022-01-01 01:00:00+00:00  today's cryptocurrency fear and greed index: 2...   \n",
       "\n",
       "                           replyCount  retweetCount  likeCount  quoteCount  \\\n",
       "date                                                                         \n",
       "2022-01-01 00:00:00+00:00           0             0         20           0   \n",
       "2022-01-01 00:00:02+00:00          20            31        211           3   \n",
       "2022-01-01 00:00:03+00:00           0             4          4           0   \n",
       "2022-01-01 00:00:06+00:00           0             0          1           0   \n",
       "2022-01-01 00:00:38+00:00           0             1          1           0   \n",
       "...                               ...           ...        ...         ...   \n",
       "2022-01-01 00:57:11+00:00           0             0          1           0   \n",
       "2022-01-01 00:57:39+00:00           0             0          8           0   \n",
       "2022-01-01 00:57:46+00:00           2             3          6           5   \n",
       "2022-01-01 00:59:21+00:00           0             0          1           0   \n",
       "2022-01-01 01:00:00+00:00           1             1          2           0   \n",
       "\n",
       "                           verified  followersCount  friendsCount  \\\n",
       "date                                                                \n",
       "2022-01-01 00:00:00+00:00      True          203116          1400   \n",
       "2022-01-01 00:00:02+00:00      True          245622           750   \n",
       "2022-01-01 00:00:03+00:00     False            1824           171   \n",
       "2022-01-01 00:00:06+00:00     False            6994           606   \n",
       "2022-01-01 00:00:38+00:00     False             411           466   \n",
       "...                             ...             ...           ...   \n",
       "2022-01-01 00:57:11+00:00     False             534          1546   \n",
       "2022-01-01 00:57:39+00:00     False            1042          1860   \n",
       "2022-01-01 00:57:46+00:00     False             555           459   \n",
       "2022-01-01 00:59:21+00:00     False            2401           244   \n",
       "2022-01-01 01:00:00+00:00     False             840             1   \n",
       "\n",
       "                           statusesCount  \n",
       "date                                      \n",
       "2022-01-01 00:00:00+00:00          53551  \n",
       "2022-01-01 00:00:02+00:00          18051  \n",
       "2022-01-01 00:00:03+00:00          10524  \n",
       "2022-01-01 00:00:06+00:00          77904  \n",
       "2022-01-01 00:00:38+00:00           2049  \n",
       "...                                  ...  \n",
       "2022-01-01 00:57:11+00:00          26283  \n",
       "2022-01-01 00:57:39+00:00          10047  \n",
       "2022-01-01 00:57:46+00:00           3126  \n",
       "2022-01-01 00:59:21+00:00           3077  \n",
       "2022-01-01 01:00:00+00:00            555  \n",
       "\n",
       "[132 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def slice_by_time_windows(df, start_date, end_date, window_seconds=0, window_minutes=0, window_hours=0):\n",
    "    assert window_seconds or window_minutes or window_hours\n",
    "    delta = timedelta(seconds=window_seconds, minutes=window_minutes, hours=window_hours)\n",
    "    tweet_sets = []\n",
    "    windows = []\n",
    "    while start_date + delta <= end_date:\n",
    "        df_slice = df[start_date:start_date+delta]\n",
    "        if not df_slice.empty:\n",
    "            tweet_sets.append(df_slice)\n",
    "            windows.append((start_date, start_date+delta))\n",
    "        start_date = start_date + delta\n",
    "    return windows, tweet_sets\n",
    "\n",
    "windows, dataset = slice_by_time_windows(\n",
    "    df,\n",
    "    start_date = df.index[0],\n",
    "    end_date = df.index[-1],\n",
    "    window_hours = 1\n",
    ")\n",
    "\n",
    "print(type(dataset))\n",
    "print(len(dataset)) # == number of tweet_sets == number of timewindows in the specified range (start_date, end_date)\n",
    "print(type(dataset[0]))\n",
    "\n",
    "# Number of tweets in the tweet_set of a specific timewindow.\n",
    "# Notice that different tweet_sets have different number of tweets\n",
    "# and thus different shapes\n",
    "print(dataset[0].shape)\n",
    "print(dataset[1].shape)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfKVNOTllkd9",
   "metadata": {
    "id": "cfKVNOTllkd9"
   },
   "outputs": [],
   "source": [
    "# Reduce size of the dataset to speed up the process\n",
    "# TODO: comment out these lines to train a model on the complete dataset!\n",
    "\n",
    "# dataset = dataset[:50]\n",
    "# windows = windows[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612518d4",
   "metadata": {
    "id": "612518d4"
   },
   "source": [
    "### Perform api calls to compute the true labels (btc price movements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57259d8b",
   "metadata": {
    "id": "57259d8b"
   },
   "outputs": [],
   "source": [
    "# Compute the true labels (output) from dataset (the input)\n",
    "# Our label is the price movement ('Positive' or 'Negative' or 'Neutral')\n",
    "\n",
    "base_url = \"https://api.kucoin.com\"\n",
    "coin_pair = \"BTC-USDT\"\n",
    "frequency = \"1min\"\n",
    "sleep_time = 1\n",
    "\n",
    "def is_bad_response(response):\n",
    "    # when too many requests are sent to the api, we receieve\n",
    "    # response = {'code': '429000', 'msg': 'Too Many Requests'}\n",
    "    return 'data' not in response.keys()\n",
    "\n",
    "def perform_api_call(start, end):\n",
    "    price_url = f\"/api/v1/market/candles?type={frequency}&symbol={coin_pair}&startAt={start}&endAt={end}\"\n",
    "    response = requests.get(base_url + price_url).json()\n",
    "    while is_bad_response(response):\n",
    "        print(f\"Error because of too many api calls on kucoin. Sleeping for {sleep_time}...\")\n",
    "        time.sleep(sleep_time)\n",
    "        response = requests.get(base_url + price_url).json()\n",
    "    return response\n",
    "        \n",
    "def btc_price_movement(start_date, end_date, threshold):\n",
    "    # TODO: To speed up the process, instead of performing 2 api calls for each\n",
    "    # time window, we can instead group many time windows in a signel api call.\n",
    "    # Keep in mind however that kucoin api returns no more than 1500 candles per call!\n",
    "    threshold = threshold * 0.01\n",
    "\n",
    "    start_to = int(time.mktime(start_date.timetuple()))\n",
    "    end_to = int(time.mktime(end_date.timetuple()))\n",
    "    start_from = start_to - 60 # in seconds\n",
    "    end_from = end_to - 60 # in seconds\n",
    "\n",
    "    # perform api calls\n",
    "    start_response = perform_api_call(start_from, start_to)\n",
    "    start_candle = start_response['data'][0]\n",
    "    end_response = perform_api_call(end_from, end_to)\n",
    "    end_candle = end_response['data'][0]\n",
    "\n",
    "    # retrieve opening prices from price candles\n",
    "    start_price = float(start_candle[1])\n",
    "    end_price = float(end_candle[1])\n",
    "    assert start_price > 0 and end_price > 0\n",
    "\n",
    "    relative_change = (end_price - start_price) / start_price\n",
    "    if (np.abs(relative_change) >= threshold):\n",
    "        change = \"positive\" if relative_change > 0 else \"negative\"\n",
    "    else:\n",
    "        change = 'neutral'\n",
    "\n",
    "    print(change)\n",
    "    return change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e00f83a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e00f83a0",
    "outputId": "be7ba56e-c5c4-4237-844b-6c689c8dd0aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "Error because of too many api calls on kucoin. Sleeping for 1...\n",
      "positive\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "# Let's consider a time window between 08:00 and 09:00.\n",
    "# We want to check whether the set of tweets published in that time window had a positive sentiment.\n",
    "# In other words whether the price jumped up following that time window.\n",
    "# Therefore we take the price at 09:00 as a base price and we compare it\n",
    "#     with the price at 09:00 + lag_in_minutes\n",
    "lag_in_minutes = 60\n",
    "\n",
    "# The threshhold above which a price movement is considered significant.\n",
    "# For instance, if the price moved by just +0.01%, and out threshhold\n",
    "#     value is 1%, then the price change (and thus the sentiment) is 'neutral'\n",
    "# NB: 'neutral' only occurs if threshhold > 0\n",
    "price_movement_threshhold = 0 # as a percentage\n",
    "\n",
    "dataset_labels = [btc_price_movement(\n",
    "    win[1],\n",
    "    win[1] + timedelta(minutes=lag_in_minutes),\n",
    "    price_movement_threshhold\n",
    ") for win in windows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "353eed91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "353eed91",
    "outputId": "506ce83e-8a2f-46df-a134-27244aae2581"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQ+klEQVR4nO3dbaxlVX3H8e+vgPiAdUCuZJwZHYtjKJo66C1iNY1CVKQvBitSqApaktEUG63aFkwTNRWD8YHEWNGxUMYWxRE1UooPiFCLCeBFx2GGAZ0KhpmMzBUBIVZa8N8XZ004xYF77j33coH1/SQ7Z+3/Xnvvde6L39lnnX3OTVUhSerD7yz2ACRJDx9DX5I6YuhLUkcMfUnqiKEvSR3Ze7EHAHDggQfWypUrF3sYkvSocu211/68qiZms88jIvRXrlzJ1NTUYg9Dkh5Vkvx0tvs4vSNJHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR15RHwjdxwrT/v3RTv3zWf+yaKdW5Lm4lEf+pI0rp4uHp3ekaSOzBj6SR6f5JokP0yyJcn7W/28JDcl2diW1a2eJB9Psi3JpiQvWOgnIUkazSjTO/cAR1bV3Un2Aa5M8rW27W+q6sIH9H81sKotLwLObo+SpEU245V+DdzdVvdpSz3ELmuAz7b9rgKWJFk6/lAlSeMaaU4/yV5JNgK7gEur6uq26Yw2hXNWkn1bbRlwy9Du21vtgcdcm2QqydT09PQYT0GSNKqRQr+q7quq1cBy4PAkzwNOBw4B/hA4APi72Zy4qtZV1WRVTU5MzOofv0iS5mhWd+9U1R3A5cDRVbWzTeHcA/wzcHjrtgNYMbTb8laTJC2yUe7emUiypLWfALwCuGH3PH2SAMcCm9suFwEntbt4jgDurKqdCzJ6SdKsjHL3zlJgfZK9GLxIbKiqi5N8O8kEEGAj8NbW/xLgGGAb8CvgzfM/bEnSXMwY+lW1CThsD/UjH6R/AaeOPzRJ0nzzG7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIjKGf5PFJrknywyRbkry/1Z+V5Ook25J8IcnjWn3ftr6tbV+5sE9BkjSqUa707wGOrKrnA6uBo5McAXwIOKuqng3cDpzS+p8C3N7qZ7V+kqRHgBlDvwbubqv7tKWAI4ELW309cGxrr2nrtO1HJcm8jViSNGcjzekn2SvJRmAXcCnwX8AdVXVv67IdWNbay4BbANr2O4Gn7uGYa5NMJZmanp4e71lIkkYyUuhX1X1VtRpYDhwOHDLuiatqXVVNVtXkxMTEuIeTJI1gVnfvVNUdwOXAi4ElSfZum5YDO1p7B7ACoG1/CnDbvIxWkjSWUe7emUiypLWfALwC2Mog/I9r3U4GvtraF7V12vZvV1XN56AlSXOz98xdWAqsT7IXgxeJDVV1cZLrgQuSfAD4AXBO638O8C9JtgG/AE5YgHFLkuZgxtCvqk3AYXuo/4TB/P4D678GXjcvo5MkzSu/kStJHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZMbQT7IiyeVJrk+yJcnbW/19SXYk2diWY4b2OT3JtiQ3JnnVQj4BSdLoZvzH6MC9wLuq6vtJngxcm+TStu2sqvrIcOckhwInAM8Fng58K8lzquq++Ry4JGn2ZrzSr6qdVfX91r4L2Aose4hd1gAXVNU9VXUTsA04fD4GK0kaz6zm9JOsBA4Drm6ltyXZlOTcJPu32jLglqHdtrOHF4kka5NMJZmanp6e9cAlSbM3cugn2Q/4EvCOqvolcDZwMLAa2Al8dDYnrqp1VTVZVZMTExOz2VWSNEcjhX6SfRgE/vlV9WWAqrq1qu6rqt8An+H+KZwdwIqh3Ze3miRpkY1y906Ac4CtVfWxofrSoW6vATa39kXACUn2TfIsYBVwzfwNWZI0V6PcvfMS4I3AdUk2ttp7gBOTrAYKuBl4C0BVbUmyAbiewZ0/p3rnjiQ9MswY+lV1JZA9bLrkIfY5AzhjjHFJkhaA38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHZgz9JCuSXJ7k+iRbkry91Q9IcmmSH7fH/Vs9ST6eZFuSTUlesNBPQpI0mlGu9O8F3lVVhwJHAKcmORQ4DbisqlYBl7V1gFcDq9qyFjh73kctSZqTGUO/qnZW1fdb+y5gK7AMWAOsb93WA8e29hrgszVwFbAkydJ5H7kkadZmNaefZCVwGHA1cFBV7WybfgYc1NrLgFuGdtveag881tokU0mmpqenZzlsSdJcjBz6SfYDvgS8o6p+Obytqgqo2Zy4qtZV1WRVTU5MTMxmV0nSHI0U+kn2YRD451fVl1v51t3TNu1xV6vvAFYM7b681SRJi2yUu3cCnANsraqPDW26CDi5tU8GvjpUP6ndxXMEcOfQNJAkaRHtPUKflwBvBK5LsrHV3gOcCWxIcgrwU+D4tu0S4BhgG/Ar4M3zOmJJ0pzNGPpVdSWQB9l81B76F3DqmOOSJC0Av5ErSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOzBj6Sc5NsivJ5qHa+5LsSLKxLccMbTs9ybYkNyZ51UINXJI0e6Nc6Z8HHL2H+llVtbotlwAkORQ4AXhu2+eTSfaar8FKksYzY+hX1XeAX4x4vDXABVV1T1XdBGwDDh9jfJKkeTTOnP7bkmxq0z/7t9oy4JahPttb7bckWZtkKsnU9PT0GMOQJI1qrqF/NnAwsBrYCXx0tgeoqnVVNVlVkxMTE3MchiRpNuYU+lV1a1XdV1W/AT7D/VM4O4AVQ12Xt5ok6RFgTqGfZOnQ6muA3Xf2XASckGTfJM8CVgHXjDdESdJ82XumDkk+D7wMODDJduC9wMuSrAYKuBl4C0BVbUmyAbgeuBc4taruW5ihS5Jma8bQr6oT91A+5yH6nwGcMc6gJEkLw2/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR2ZMfSTnJtkV5LNQ7UDklya5Mftcf9WT5KPJ9mWZFOSFyzk4CVJszPKlf55wNEPqJ0GXFZVq4DL2jrAq4FVbVkLnD0/w5QkzYcZQ7+qvgP84gHlNcD61l4PHDtU/2wNXAUsSbJ0vgYrSRrPXOf0D6qqna39M+Cg1l4G3DLUb3ur/ZYka5NMJZmanp6e4zAkSbMx9ge5VVVAzWG/dVU1WVWTExMT4w5DkjSCuYb+rbunbdrjrlbfAawY6re81SRJjwBzDf2LgJNb+2Tgq0P1k9pdPEcAdw5NA0mSFtneM3VI8nngZcCBSbYD7wXOBDYkOQX4KXB8634JcAywDfgV8OYFGLMkaY5mDP2qOvFBNh21h74FnDruoCRJC8Nv5EpSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSMz/mP0h5LkZuAu4D7g3qqaTHIA8AVgJXAzcHxV3T7eMCVJ82E+rvRfXlWrq2qyrZ8GXFZVq4DL2rok6RFgIaZ31gDrW3s9cOwCnEOSNAfjhn4B30xybZK1rXZQVe1s7Z8BB+1pxyRrk0wlmZqenh5zGJKkUYw1pw+8tKp2JHkacGmSG4Y3VlUlqT3tWFXrgHUAk5OTe+wjSZpfY13pV9WO9rgL+ApwOHBrkqUA7XHXuIOUJM2POYd+kiclefLuNvBKYDNwEXBy63Yy8NVxBylJmh/jTO8cBHwlye7jfK6qvp7ke8CGJKcAPwWOH3+YkqT5MOfQr6qfAM/fQ/024KhxBiVJWhh+I1eSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR1ZsNBPcnSSG5NsS3LaQp1HkjS6BQn9JHsB/wi8GjgUODHJoQtxLknS6BbqSv9wYFtV/aSq/ge4AFizQOeSJI1o7wU67jLglqH17cCLhjskWQusbat3J7lxjuc6EPj5HPcdSz60GGeV9FiSD42VYc+c7Q4LFfozqqp1wLpxj5Nkqqom52FIkvSwe7gzbKGmd3YAK4bWl7eaJGkRLVTofw9YleRZSR4HnABctEDnkiSNaEGmd6rq3iRvA74B7AWcW1VbFuJczMMUkSQtooc1w1JVD+f5JEmLyG/kSlJHDH1J6sijOvSTvDXJSa39piRPH9r2T34LWNKjSZIlSf5yaP3pSS6c13M8Vub0k1wBvLuqphZ7LJI0F0lWAhdX1fMW6hyLdqWfZGWSG5Kcn2RrkguTPDHJUUl+kOS6JOcm2bf1PzPJ9Uk2JflIq70vybuTHAdMAucn2ZjkCUmuSDLZ3g18eOi8b0ryidZ+Q5Jr2j6fbr8ZJEl71HJra5LPJNmS5Jstbw5O8vUk1yb5zySHtP4HJ7mq5dkHktzd6vsluSzJ99u23T9TcyZwcMukD7fzbW77XJXkuUNj2Z1xT2pZeU3Lzof+yZuqWpQFWAkU8JK2fi7w9wx+vuE5rfZZ4B3AU4Ebuf+dyZL2+D4GV/cAVwCTQ8e/gsELwQSD3wHaXf8a8FLg94F/A/Zp9U8CJy3W38PFxeWRv7TcuhdY3dY3AG8ALgNWtdqLgG+39sXAia39VuDu1t4b+N3WPhDYBqQdf/MDzre5tf8aeH9rLwVubO0PAm9o7SXAj4AnPdhzWOw5/Vuq6rut/a/AUcBNVfWjVlsP/DFwJ/Br4Jwkfwr8atQTVNU08JMkRyR5KnAI8N12rhcC30uysa3/3jw8J0mPbTdV1cbWvpZBMP8R8MWWJZ9mEMoALwa+2NqfGzpGgA8m2QR8i8HvlR00w3k3AMe19vHA7rn+VwKntXNfATweeMaDHWTRfnuneeAHCncwuKr//50GX/Y6nEEwHwe8DThyFue5gMEf6QbgK1VVSQKsr6rT5zRySb26Z6h9H4OwvqOqVs/iGK9nMAvxwqr63yQ3MwjrB1VVO5LcluQPgD9j8M4BBi8gr62qkX60crGv9J+R5MWt/efAFLAyybNb7Y3AfyTZD3hKVV3C4C3O8/dwrLuAJz/Ieb7C4KedT2TwAgCDt2PHJXkaQJIDksz6F+skde+XwE1JXgeQgd0ZdRXw2tY+YWifpwC7WuC/nPt/LfOhcgzgC8DfMsjDTa32DeCv2oUsSQ57qMEudujfCJyaZCuwP3AW8GYGb5OuA34DfIrBH+Hi9lboSuCdezjWecCndn+QO7yhqm4HtgLPrKprWu16Bp8hfLMd91Luf0smSbPxeuCUJD8EtnD//w95B/DOljHPZjBVDXA+MNly7iQGsxBU1W3Ad5NsHr4BZciFDF48NgzV/gHYB9iUZEtbf1CLdsvmw3FrkiQtpiRPBP67TSmfwOBD3UX9h1KLPacvSY9lLwQ+0aZe7gD+YpHH89j5cpYkaWaLPacvSXoYGfqS1BFDX5I6YuhLUkcMfUnqyP8BRPv+x7Q7u9sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the distribution of the sentiments\n",
    "plt.hist(dataset_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "J6YqwH8eJ2UK",
   "metadata": {
    "id": "J6YqwH8eJ2UK"
   },
   "outputs": [],
   "source": [
    "# Hot encoding for the label classes\n",
    "hot_encoding = pd.get_dummies(np.squeeze(dataset_labels))\n",
    "classes = np.array(hot_encoding.columns).astype('str')\n",
    "hot_encoding = tf.convert_to_tensor(hot_encoding)\n",
    "dataset_labels = hot_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f1010",
   "metadata": {
    "id": "ff3f1010"
   },
   "source": [
    "### Make sure all tweet sets contain the same number of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a682e045",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "a682e045",
    "outputId": "13a8c2fa-43fc-4211-b9e2-cb9fc2f8f7b1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of timewindows/ tweet_sets:  719\n",
      "Number of discarded timewindows:  21\n"
     ]
    }
   ],
   "source": [
    "tweet_set_size = 100\n",
    "\n",
    "# Visualize the distribution of the tweet sets sizes\n",
    "plt.hist([tweet_set_df.shape[0] for tweet_set_df in dataset], bins=100)\n",
    "plt.axvline(x=tweet_set_size, color=\"red\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Total number of timewindows/ tweet_sets: \", len(dataset))\n",
    "print(\"Number of discarded timewindows: \", len([1 for tset in dataset if tset.shape[0] < tweet_set_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94b80853",
   "metadata": {
    "id": "94b80853"
   },
   "outputs": [],
   "source": [
    "# discard tweet sets (and respective labels) that have less than tweet_set_size tweets\n",
    "remaining_dataset = []\n",
    "remaining_dataset_labels = []\n",
    "for i, tweet_set_df in enumerate(dataset):\n",
    "    if tweet_set_df.shape[0] >= tweet_set_size:\n",
    "        remaining_dataset.append(tweet_set_df)\n",
    "        remaining_dataset_labels.append(dataset_labels[i])\n",
    "dataset = remaining_dataset\n",
    "dataset_labels = remaining_dataset_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ebaa6c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "0ebaa6c7",
    "outputId": "1aebb926-d67e-41bc-9243-7de489fff437"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0b3d66e2-abaf-45d2-9cd3-c2ccc30d1fda\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>verified</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>statusesCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:40:33+00:00</th>\n",
       "      <td>the latest #bitcoin block 716607 with 5 transa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>322</td>\n",
       "      <td>234</td>\n",
       "      <td>23022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:55:33+00:00</th>\n",
       "      <td>the latest #bitcoin block 716609 with 1051 tra...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>322</td>\n",
       "      <td>234</td>\n",
       "      <td>23022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:49:03+00:00</th>\n",
       "      <td>#twitter is at turning point since left. can a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>337</td>\n",
       "      <td>4952</td>\n",
       "      <td>2540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:17:33+00:00</th>\n",
       "      <td>happy new year fellow #bitcoin friends</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>375</td>\n",
       "      <td>647</td>\n",
       "      <td>2984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:47:32+00:00</th>\n",
       "      <td>energy sector and tech lobbyists will become ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>396</td>\n",
       "      <td>595</td>\n",
       "      <td>3928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:08:00+00:00</th>\n",
       "      <td>you cannot comprehend the strengths of #bitcoi...</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>116343</td>\n",
       "      <td>113</td>\n",
       "      <td>33734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:33:44+00:00</th>\n",
       "      <td>\"#binance has issued a notice to users, withou...</td>\n",
       "      <td>82</td>\n",
       "      <td>34</td>\n",
       "      <td>145</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>2428441</td>\n",
       "      <td>920</td>\n",
       "      <td>25770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:02+00:00</th>\n",
       "      <td>most people underestimate the impact #bitcoin ...</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>211</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>245622</td>\n",
       "      <td>750</td>\n",
       "      <td>18051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:01:22+00:00</th>\n",
       "      <td>in 2017, miners attempted to assert control ov...</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>310</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>48961</td>\n",
       "      <td>154</td>\n",
       "      <td>73822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:52:40+00:00</th>\n",
       "      <td>happy new year #bitcoin'rs!!!</td>\n",
       "      <td>61</td>\n",
       "      <td>26</td>\n",
       "      <td>803</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>185014</td>\n",
       "      <td>591</td>\n",
       "      <td>45508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b3d66e2-abaf-45d2-9cd3-c2ccc30d1fda')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0b3d66e2-abaf-45d2-9cd3-c2ccc30d1fda button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0b3d66e2-abaf-45d2-9cd3-c2ccc30d1fda');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                                     content  \\\n",
       "date                                                                           \n",
       "2022-01-01 00:40:33+00:00  the latest #bitcoin block 716607 with 5 transa...   \n",
       "2022-01-01 00:55:33+00:00  the latest #bitcoin block 716609 with 1051 tra...   \n",
       "2022-01-01 00:49:03+00:00  #twitter is at turning point since left. can a...   \n",
       "2022-01-01 00:17:33+00:00             happy new year fellow #bitcoin friends   \n",
       "2022-01-01 00:47:32+00:00   energy sector and tech lobbyists will become ...   \n",
       "...                                                                      ...   \n",
       "2022-01-01 00:08:00+00:00  you cannot comprehend the strengths of #bitcoi...   \n",
       "2022-01-01 00:33:44+00:00  \"#binance has issued a notice to users, withou...   \n",
       "2022-01-01 00:00:02+00:00  most people underestimate the impact #bitcoin ...   \n",
       "2022-01-01 00:01:22+00:00  in 2017, miners attempted to assert control ov...   \n",
       "2022-01-01 00:52:40+00:00                      happy new year #bitcoin'rs!!!   \n",
       "\n",
       "                           replyCount  retweetCount  likeCount  quoteCount  \\\n",
       "date                                                                         \n",
       "2022-01-01 00:40:33+00:00           0             0          1           0   \n",
       "2022-01-01 00:55:33+00:00           0             1          1           0   \n",
       "2022-01-01 00:49:03+00:00           1             0          1           0   \n",
       "2022-01-01 00:17:33+00:00           0             0          1           0   \n",
       "2022-01-01 00:47:32+00:00           0             0          1           0   \n",
       "...                               ...           ...        ...         ...   \n",
       "2022-01-01 00:08:00+00:00          44            54        136           4   \n",
       "2022-01-01 00:33:44+00:00          82            34        145           3   \n",
       "2022-01-01 00:00:02+00:00          20            31        211           3   \n",
       "2022-01-01 00:01:22+00:00          18            31        310           8   \n",
       "2022-01-01 00:52:40+00:00          61            26        803           0   \n",
       "\n",
       "                           verified  followersCount  friendsCount  \\\n",
       "date                                                                \n",
       "2022-01-01 00:40:33+00:00     False             322           234   \n",
       "2022-01-01 00:55:33+00:00     False             322           234   \n",
       "2022-01-01 00:49:03+00:00     False             337          4952   \n",
       "2022-01-01 00:17:33+00:00     False             375           647   \n",
       "2022-01-01 00:47:32+00:00     False             396           595   \n",
       "...                             ...             ...           ...   \n",
       "2022-01-01 00:08:00+00:00     False          116343           113   \n",
       "2022-01-01 00:33:44+00:00      True         2428441           920   \n",
       "2022-01-01 00:00:02+00:00      True          245622           750   \n",
       "2022-01-01 00:01:22+00:00     False           48961           154   \n",
       "2022-01-01 00:52:40+00:00     False          185014           591   \n",
       "\n",
       "                           statusesCount  \n",
       "date                                      \n",
       "2022-01-01 00:40:33+00:00          23022  \n",
       "2022-01-01 00:55:33+00:00          23022  \n",
       "2022-01-01 00:49:03+00:00           2540  \n",
       "2022-01-01 00:17:33+00:00           2984  \n",
       "2022-01-01 00:47:32+00:00           3928  \n",
       "...                                  ...  \n",
       "2022-01-01 00:08:00+00:00          33734  \n",
       "2022-01-01 00:33:44+00:00          25770  \n",
       "2022-01-01 00:00:02+00:00          18051  \n",
       "2022-01-01 00:01:22+00:00          73822  \n",
       "2022-01-01 00:52:40+00:00          45508  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trim_tweet_set(tweet_set_df, goal_size):\n",
    "    # tweets with higher like and follower counts are taken first\n",
    "    tweet_set_df = tweet_set_df.sort_values(['likeCount','followersCount'])\n",
    "    return tweet_set_df.tail(goal_size)\n",
    "\n",
    "trim_tweet_set(dataset[0], tweet_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa42c7bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa42c7bf",
    "outputId": "adedcfed-47d8-40ef-8b3e-d583a38b2e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698\n",
      "698\n",
      "(100, 9)\n",
      "(100, 9)\n"
     ]
    }
   ],
   "source": [
    "# trim tweet_sets that contain more than tweet_set_size tweets\n",
    "dataset = [trim_tweet_set(tweet_set_df, tweet_set_size) for tweet_set_df in dataset]\n",
    "print(len(dataset))\n",
    "print(len(dataset_labels))\n",
    "print(dataset[0].shape)\n",
    "print(dataset[1].shape)\n",
    "\n",
    "# All tweet sets must now have the same shape\n",
    "assert all([tset.shape == dataset[0].shape for tset in dataset])\n",
    "assert dataset[0].shape[0] == tweet_set_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912a296",
   "metadata": {
    "id": "8912a296"
   },
   "source": [
    "### Divide the tweets into text and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8426e29d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8426e29d",
    "outputId": "9bf1e21a-632f-4905-bed7-b7c77a93059b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(698, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "X_texts = [tweet_set_df['content'].values for tweet_set_df in dataset]\n",
    "X_texts = np.expand_dims(np.array(X_texts), axis=-1)\n",
    "print(X_texts.shape) # number of tweet sets, number of tweets per set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5c6305d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5c6305d",
    "outputId": "7909a3f6-8eec-40ec-8668-d7f32ba154d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(698, 100, 7)\n"
     ]
    }
   ],
   "source": [
    "metadata_columns = [\n",
    "    'replyCount',\n",
    "    'retweetCount',\n",
    "    'likeCount',\n",
    "    'quoteCount',\n",
    "    'followersCount',\n",
    "    'friendsCount',\n",
    "    'statusesCount'\n",
    "]\n",
    "X_metadata = [tweet_set_df[metadata_columns].values for tweet_set_df in dataset]\n",
    "X_metadata = np.array(X_metadata)\n",
    "print(X_metadata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0659903a",
   "metadata": {
    "id": "0659903a"
   },
   "source": [
    "### Tokenize the tweet texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64fe40ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185,
     "referenced_widgets": [
      "69e8214909714e0f807c1e412131738f",
      "c83673ba72d64820a995fe09c1095774",
      "3ca44c9056954f3cad6f0439c55a34c5",
      "83179fbd17074490bd3c3768310a124e",
      "3f9aed00cb634ab9906d24107eccaaaf",
      "579f5c425dcf44d89e55564ef4a9e46f",
      "2b485ca0d09d44e5aaacda69367bd1a0",
      "7ab2843c0f2c45ad831d3a190ab4f1a8",
      "a892d46c51974e4480c5a82e54e01317",
      "e81d63e9dff74ba98611bf97b5ec5a19",
      "e3f383497a7f416cb5f499f09db13171",
      "a643143978d74764a28e17ff2a7a0e70",
      "cc988eb32e134a7d93e7c79e84fd3568",
      "1f07cfb0aebf4fc4af683e87716e20df",
      "d95ca002c7d04e09bebda6970b6e7d48",
      "e67592c58bc745459206df5c7a81595f",
      "90d0cd545c364bd3a28dd0e5f72a75b7",
      "86c69accd07b4a76ac5eb7d9811fd310",
      "ca3eb273c3ef4c9d9dfc2d37c2b54873",
      "2846b77e882a4527bd23f461a8124114",
      "3c5cd03826a94215a0dc82b6c3784ec0",
      "0622b7f9f43143369869eeb453161535",
      "7bc912675026452fa4e3ba62fa56fdff",
      "6b604f830c234e01995961f16da94710",
      "731fe13490b646c1baca92e90f0cb02a",
      "24ee118ed5de4fa38a4e611a2b2c79e2",
      "ddf67949161c4ebba69ee8d1f72a7420",
      "1a715dabd20d4412a2fa98f737e82ba0",
      "f46a93115ce34c4385fa5cf0924c7f51",
      "d0ae058c993742849daecf388e3c8702",
      "bb498751e01a4a09b7daa9ed0719b5fa",
      "cd19413554d64a38bf0738fc2939b77b",
      "cd52a5d7600c49528aec12e2e3d08707"
     ]
    },
    "id": "64fe40ba",
    "outputId": "215c69e9-6f5f-4892-bd9e-b961f98a31f2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e8214909714e0f807c1e412131738f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/558 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a643143978d74764a28e17ff2a7a0e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/824k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc912675026452fa4e3ba62fa56fdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Please install emoji: pip3 install emoji\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 1659, 220, 33, 17, 11, 1156, 12, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Must set flag \"normalization=True\" since we are using raw tweets\n",
    "# This ensures that links, emojis etc. are properly encoded to serve as input for the Bertweet model\n",
    "# Refer to: https://github.com/VinAIResearch/BERTweet\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, normalization=True)\n",
    "tokenizer(['Hello world this is a test !'], padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2f27878",
   "metadata": {
    "id": "b2f27878",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_encodings = []\n",
    "for tweet_set in X_texts:\n",
    "    tweet_set_encoded = []\n",
    "    for tweet_text in tweet_set:\n",
    "        text_encoding = tokenizer(tweet_text.astype('str')[0], padding='max_length',\n",
    "                                  truncation=True)\n",
    "        tweet_set_encoded.append(text_encoding)\n",
    "    X_encodings.append(tweet_set_encoded)\n",
    "\n",
    "X_texts_input_ids = []\n",
    "X_texts_attention_masks = []\n",
    "X_texts_token_type_ids = []\n",
    "for tweet_set in X_encodings:\n",
    "    tweet_set_input_ids = []\n",
    "    tweet_set_attention_masks = []\n",
    "    tweet_set_token_type_ids = []\n",
    "    for tweet_text in tweet_set:\n",
    "        tweet_set_input_ids.append(tweet_text[\"input_ids\"])\n",
    "        tweet_set_attention_masks.append(tweet_text[\"attention_mask\"])\n",
    "        tweet_set_token_type_ids.append(tweet_text[\"token_type_ids\"])\n",
    "    X_texts_input_ids.append(tweet_set_input_ids)\n",
    "    X_texts_attention_masks.append(tweet_set_attention_masks)\n",
    "    X_texts_token_type_ids.append(tweet_set_token_type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a163b4",
   "metadata": {
    "id": "f1a163b4"
   },
   "source": [
    "### Extract text features using the bertweet model (WARNING: takes a LOT of time without GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec270a17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0acb15c8dddd40dbb1e20009fd6206b7",
      "ab558a3427ec4c0197d369cf117aed29",
      "72cde91e43434eca9634cd68001d3ef4",
      "a70cfa850b904f25849170d8cb513772",
      "38b7d2561eab4df6873a349a3b76c034",
      "b4fb361427c640f5bf3e12445e10f2e4",
      "fb3333664d124a26983e0b9cb6b6a1b3",
      "43603bb6aaea4031929b550532549ea3",
      "b028a2da80ec4fdb8aaeaefe4cea0954",
      "0f4890c267054fb78eee0b1c84002319",
      "f380782a498440588959413792ca22da"
     ]
    },
    "id": "ec270a17",
    "outputId": "ace0ca7a-7f7b-48ba-d56b-a00e2fba41fe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acb15c8dddd40dbb1e20009fd6206b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/705M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at vinai/bertweet-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at vinai/bertweet-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n"
     ]
    }
   ],
   "source": [
    "# Last step: extract text features using the bertweet model\n",
    "\n",
    "bertwitter_encoder_model = TFAutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "\n",
    "X_texts_features = []\n",
    "for i in range(len(X_texts_input_ids)):\n",
    "    print(i)\n",
    "    bert_encoding = bertwitter_encoder_model(\n",
    "        input_ids = tf.convert_to_tensor(X_texts_input_ids[i]),\n",
    "        attention_mask = tf.convert_to_tensor(X_texts_attention_masks[i]),\n",
    "        token_type_ids = tf.convert_to_tensor(X_texts_token_type_ids[i])\n",
    "    )\n",
    "    X_texts_features.append(bert_encoding['pooler_output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea39977",
   "metadata": {
    "id": "5ea39977"
   },
   "source": [
    "### Final data preparation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "VDcZ5jx8BEXp",
   "metadata": {
    "id": "VDcZ5jx8BEXp"
   },
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "dataset_size = len(dataset_labels)\n",
    "shuffler = np.random.permutation(dataset_size)\n",
    "\n",
    "X_texts_features = np.array(X_texts_features)[shuffler]\n",
    "X_metadata = np.array(X_metadata)[shuffler]\n",
    "dataset_labels = np.array(dataset_labels)[shuffler]\n",
    "\n",
    "# Convert to tf tensors\n",
    "X_texts_features = tf.convert_to_tensor(X_texts_features)\n",
    "X_metadata = tf.convert_to_tensor(X_metadata)\n",
    "labels = tf.convert_to_tensor(dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3JG_LSyhBdyZ",
   "metadata": {
    "id": "3JG_LSyhBdyZ"
   },
   "outputs": [],
   "source": [
    "# Split dataset into training and testing set\n",
    "test_ratio = 0.15\n",
    "test_size = int(test_ratio * dataset_size)\n",
    "train_size = dataset_size - test_size\n",
    "\n",
    "X_train = [X_texts_features[:train_size], X_metadata[:train_size]]\n",
    "y_train = labels[:train_size]\n",
    "X_test = [X_texts_features[train_size:], X_metadata[train_size:]]\n",
    "y_test = labels[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61100ad5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61100ad5",
    "outputId": "54e7a794-5e56-4381-d117-a0f628a0b451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 100, 768)\n",
      "(594, 100, 7)\n",
      "(594, 2)\n",
      "(104, 100, 768)\n",
      "(104, 100, 7)\n",
      "(104, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)\n",
    "print(X_train[1].shape)\n",
    "print(y_train.shape)\n",
    "print(X_test[0].shape)\n",
    "print(X_test[1].shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3271c3",
   "metadata": {
    "id": "ce3271c3"
   },
   "source": [
    "# 4. Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f2e19fb",
   "metadata": {
    "id": "5f2e19fb"
   },
   "outputs": [],
   "source": [
    "# We noticed that after some epochs of training, we get a 'nan' loss.\n",
    "# After lots of research and debugging, we managed to solve the issue by adding epsilon.\n",
    "# We believe that the issue was caused by the ReLu layer before the softmax layer:\n",
    "# When input to ReLu is negative ==> it's output is 0 ==> scores equals 0\n",
    "# ==> the weighted average layer divides by 0 ==> final output is 'nan'\n",
    "epsilon = 0.001\n",
    "\n",
    "# If threshhold == 0: binary classification ('positive' or 'negative')\n",
    "# If threshhold > 0: classification with 3 classes (includes 'neutral')\n",
    "output_units = 2 if price_movement_threshhold == 0 else 3\n",
    "\n",
    "class WeightedAverageLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(WeightedAverageLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        return\n",
    "\n",
    "    def call(self, inputs):\n",
    "        values, scores = inputs\n",
    "        scores = scores + epsilon\n",
    "        values = values + epsilon\n",
    "        return tf.reduce_sum(values * scores, axis=-2) / tf.reduce_sum(scores, axis=-2)\n",
    "\n",
    "# We use 2 output units (hot_encoded categories) with softmax\n",
    "#     instead of a single output unit with sigmoid.\n",
    "# This is believed to yield a better accuracy\n",
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.dropout = tf.keras.layers.Dropout(0.1)\n",
    "        self.individual_classifier = tf.keras.layers.Dense(output_units,\n",
    "                                        activation=\"softmax\", name=\"individual-classifier\")\n",
    "        self.hidden_scorer_layer = tf.keras.layers.Dense(64, activation=\"relu\")\n",
    "        self.scorer = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"scorer\")\n",
    "        self.averaging_layer = WeightedAverageLayer()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # text_features.shape = (None, tweet_set_size, 768)\n",
    "        # metadatas.shape = (None, tweet_set_size, 7)\n",
    "        text_features, metadatas = inputs\n",
    "\n",
    "        # Compute individual tweet sentiments\n",
    "        features = self.dropout(text_features)\n",
    "        sentiments = self.individual_classifier(features)\n",
    "\n",
    "        # Compute individual tweet scores\n",
    "        hidden = self.hidden_scorer_layer(metadatas)\n",
    "        scores = self.scorer(hidden)\n",
    "\n",
    "        # Perform a weighted average over individual tweet sentiments according to\n",
    "        # their respective scores\n",
    "        output = self.averaging_layer((sentiments, scores))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57b86fe9",
   "metadata": {
    "id": "57b86fe9"
   },
   "outputs": [],
   "source": [
    "model = CustomModel()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99641eb7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99641eb7",
    "outputId": "d7a84f60-2b72-43f2-9c55-d0df03ba22c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "594/594 [==============================] - 4s 4ms/step - loss: 0.7216 - accuracy: 0.5253 - val_loss: 0.6931 - val_accuracy: 0.5192\n",
      "Epoch 2/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7109 - accuracy: 0.5505 - val_loss: 0.7381 - val_accuracy: 0.5192\n",
      "Epoch 3/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7191 - accuracy: 0.5051 - val_loss: 0.7126 - val_accuracy: 0.4808\n",
      "Epoch 4/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7058 - accuracy: 0.5185 - val_loss: 0.6971 - val_accuracy: 0.5000\n",
      "Epoch 5/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7177 - accuracy: 0.5387 - val_loss: 0.8036 - val_accuracy: 0.4808\n",
      "Epoch 6/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7259 - accuracy: 0.4966 - val_loss: 0.7306 - val_accuracy: 0.4808\n",
      "Epoch 7/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7393 - accuracy: 0.4714 - val_loss: 0.6948 - val_accuracy: 0.5192\n",
      "Epoch 8/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7186 - accuracy: 0.4949 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 9/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.7113 - accuracy: 0.5202 - val_loss: 0.7397 - val_accuracy: 0.4808\n",
      "Epoch 10/1000\n",
      "594/594 [==============================] - 4s 7ms/step - loss: 0.7182 - accuracy: 0.5185 - val_loss: 0.7064 - val_accuracy: 0.5096\n",
      "Epoch 11/1000\n",
      "594/594 [==============================] - 4s 6ms/step - loss: 0.7129 - accuracy: 0.5219 - val_loss: 0.7099 - val_accuracy: 0.4808\n",
      "Epoch 12/1000\n",
      "594/594 [==============================] - 4s 7ms/step - loss: 0.6988 - accuracy: 0.5421 - val_loss: 0.8865 - val_accuracy: 0.4808\n",
      "Epoch 13/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.7107 - accuracy: 0.5370 - val_loss: 0.7213 - val_accuracy: 0.4808\n",
      "Epoch 14/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7162 - accuracy: 0.4949 - val_loss: 0.7055 - val_accuracy: 0.5096\n",
      "Epoch 15/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7089 - accuracy: 0.5152 - val_loss: 0.7020 - val_accuracy: 0.4615\n",
      "Epoch 16/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6994 - accuracy: 0.5253 - val_loss: 0.7256 - val_accuracy: 0.5096\n",
      "Epoch 17/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7030 - accuracy: 0.5168 - val_loss: 0.7193 - val_accuracy: 0.4904\n",
      "Epoch 18/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7044 - accuracy: 0.5101 - val_loss: 0.7349 - val_accuracy: 0.4904\n",
      "Epoch 19/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7028 - accuracy: 0.5084 - val_loss: 0.7142 - val_accuracy: 0.4904\n",
      "Epoch 20/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6970 - accuracy: 0.5455 - val_loss: 0.7228 - val_accuracy: 0.4615\n",
      "Epoch 21/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6958 - accuracy: 0.5101 - val_loss: 0.8684 - val_accuracy: 0.5192\n",
      "Epoch 22/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6941 - accuracy: 0.5404 - val_loss: 0.7228 - val_accuracy: 0.5096\n",
      "Epoch 23/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7140 - accuracy: 0.5404 - val_loss: 0.7467 - val_accuracy: 0.4808\n",
      "Epoch 24/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6965 - accuracy: 0.5370 - val_loss: 0.7592 - val_accuracy: 0.4808\n",
      "Epoch 25/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7076 - accuracy: 0.5135 - val_loss: 0.7215 - val_accuracy: 0.4423\n",
      "Epoch 26/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6927 - accuracy: 0.5354 - val_loss: 0.7286 - val_accuracy: 0.4423\n",
      "Epoch 27/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6890 - accuracy: 0.5455 - val_loss: 0.7711 - val_accuracy: 0.4808\n",
      "Epoch 28/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6981 - accuracy: 0.5387 - val_loss: 0.7302 - val_accuracy: 0.4904\n",
      "Epoch 29/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6960 - accuracy: 0.5269 - val_loss: 0.7308 - val_accuracy: 0.5096\n",
      "Epoch 30/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6828 - accuracy: 0.5707 - val_loss: 0.7269 - val_accuracy: 0.4423\n",
      "Epoch 31/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6906 - accuracy: 0.5522 - val_loss: 0.7988 - val_accuracy: 0.4808\n",
      "Epoch 32/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6867 - accuracy: 0.5303 - val_loss: 0.7332 - val_accuracy: 0.4423\n",
      "Epoch 33/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6894 - accuracy: 0.5253 - val_loss: 0.7650 - val_accuracy: 0.5000\n",
      "Epoch 34/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6959 - accuracy: 0.5168 - val_loss: 0.7442 - val_accuracy: 0.4808\n",
      "Epoch 35/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6869 - accuracy: 0.5152 - val_loss: 0.7512 - val_accuracy: 0.5000\n",
      "Epoch 36/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6904 - accuracy: 0.5556 - val_loss: 0.7433 - val_accuracy: 0.4423\n",
      "Epoch 37/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6804 - accuracy: 0.5135 - val_loss: 0.7642 - val_accuracy: 0.5096\n",
      "Epoch 38/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6766 - accuracy: 0.5673 - val_loss: 0.8712 - val_accuracy: 0.4904\n",
      "Epoch 39/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6784 - accuracy: 0.5606 - val_loss: 0.7293 - val_accuracy: 0.4615\n",
      "Epoch 40/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6744 - accuracy: 0.5488 - val_loss: 0.7479 - val_accuracy: 0.4519\n",
      "Epoch 41/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6805 - accuracy: 0.5438 - val_loss: 0.7377 - val_accuracy: 0.4615\n",
      "Epoch 42/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6797 - accuracy: 0.5152 - val_loss: 0.7508 - val_accuracy: 0.4904\n",
      "Epoch 43/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6806 - accuracy: 0.5404 - val_loss: 0.7477 - val_accuracy: 0.4519\n",
      "Epoch 44/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6709 - accuracy: 0.5438 - val_loss: 0.7379 - val_accuracy: 0.4808\n",
      "Epoch 45/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6724 - accuracy: 0.5606 - val_loss: 0.7418 - val_accuracy: 0.4615\n",
      "Epoch 46/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6792 - accuracy: 0.5505 - val_loss: 0.7439 - val_accuracy: 0.4423\n",
      "Epoch 47/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6706 - accuracy: 0.5606 - val_loss: 0.7336 - val_accuracy: 0.4615\n",
      "Epoch 48/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7033 - accuracy: 0.5505 - val_loss: 0.7070 - val_accuracy: 0.5288\n",
      "Epoch 49/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6989 - accuracy: 0.5455 - val_loss: 0.7299 - val_accuracy: 0.4135\n",
      "Epoch 50/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7067 - accuracy: 0.5253 - val_loss: 0.7331 - val_accuracy: 0.4808\n",
      "Epoch 51/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6965 - accuracy: 0.5606 - val_loss: 0.7558 - val_accuracy: 0.4712\n",
      "Epoch 52/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6979 - accuracy: 0.5741 - val_loss: 0.7563 - val_accuracy: 0.4808\n",
      "Epoch 53/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6865 - accuracy: 0.5539 - val_loss: 0.8465 - val_accuracy: 0.4519\n",
      "Epoch 54/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6902 - accuracy: 0.5522 - val_loss: 0.8179 - val_accuracy: 0.4615\n",
      "Epoch 55/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6902 - accuracy: 0.5690 - val_loss: 0.7217 - val_accuracy: 0.4904\n",
      "Epoch 56/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6804 - accuracy: 0.5673 - val_loss: 0.8512 - val_accuracy: 0.4904\n",
      "Epoch 57/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6730 - accuracy: 0.5774 - val_loss: 0.7514 - val_accuracy: 0.4423\n",
      "Epoch 58/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6660 - accuracy: 0.5455 - val_loss: 0.7573 - val_accuracy: 0.4519\n",
      "Epoch 59/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6749 - accuracy: 0.5438 - val_loss: 0.7531 - val_accuracy: 0.4615\n",
      "Epoch 60/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6722 - accuracy: 0.5421 - val_loss: 0.7455 - val_accuracy: 0.4231\n",
      "Epoch 61/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6675 - accuracy: 0.5606 - val_loss: 0.7479 - val_accuracy: 0.5000\n",
      "Epoch 62/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6680 - accuracy: 0.5640 - val_loss: 0.7562 - val_accuracy: 0.4712\n",
      "Epoch 63/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6770 - accuracy: 0.6010 - val_loss: 0.8652 - val_accuracy: 0.5000\n",
      "Epoch 64/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.7054 - accuracy: 0.5758 - val_loss: 0.7851 - val_accuracy: 0.4615\n",
      "Epoch 65/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6803 - accuracy: 0.5623 - val_loss: 0.7770 - val_accuracy: 0.4712\n",
      "Epoch 66/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6619 - accuracy: 0.5909 - val_loss: 0.7996 - val_accuracy: 0.4904\n",
      "Epoch 67/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6792 - accuracy: 0.5808 - val_loss: 0.8040 - val_accuracy: 0.4519\n",
      "Epoch 68/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6875 - accuracy: 0.5505 - val_loss: 0.7371 - val_accuracy: 0.4904\n",
      "Epoch 69/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6736 - accuracy: 0.5657 - val_loss: 0.7506 - val_accuracy: 0.4904\n",
      "Epoch 70/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6729 - accuracy: 0.5690 - val_loss: 0.7421 - val_accuracy: 0.4615\n",
      "Epoch 71/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6567 - accuracy: 0.5892 - val_loss: 0.7344 - val_accuracy: 0.4519\n",
      "Epoch 72/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6711 - accuracy: 0.5690 - val_loss: 0.7350 - val_accuracy: 0.4904\n",
      "Epoch 73/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6641 - accuracy: 0.5404 - val_loss: 0.7602 - val_accuracy: 0.4327\n",
      "Epoch 74/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6723 - accuracy: 0.5673 - val_loss: 0.7680 - val_accuracy: 0.4904\n",
      "Epoch 75/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6619 - accuracy: 0.5707 - val_loss: 0.7533 - val_accuracy: 0.4519\n",
      "Epoch 76/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6666 - accuracy: 0.5842 - val_loss: 0.7449 - val_accuracy: 0.4712\n",
      "Epoch 77/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6769 - accuracy: 0.5758 - val_loss: 0.7527 - val_accuracy: 0.4423\n",
      "Epoch 78/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6748 - accuracy: 0.6010 - val_loss: 0.7781 - val_accuracy: 0.4615\n",
      "Epoch 79/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6730 - accuracy: 0.5909 - val_loss: 0.7111 - val_accuracy: 0.4712\n",
      "Epoch 80/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6896 - accuracy: 0.5875 - val_loss: 0.7557 - val_accuracy: 0.4808\n",
      "Epoch 81/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6725 - accuracy: 0.5993 - val_loss: 0.7599 - val_accuracy: 0.4135\n",
      "Epoch 82/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6907 - accuracy: 0.5943 - val_loss: 0.7534 - val_accuracy: 0.4615\n",
      "Epoch 83/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6756 - accuracy: 0.6111 - val_loss: 0.8121 - val_accuracy: 0.5192\n",
      "Epoch 84/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6572 - accuracy: 0.6077 - val_loss: 0.7389 - val_accuracy: 0.4423\n",
      "Epoch 85/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6581 - accuracy: 0.6111 - val_loss: 0.7425 - val_accuracy: 0.4135\n",
      "Epoch 86/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6774 - accuracy: 0.5859 - val_loss: 0.7426 - val_accuracy: 0.4519\n",
      "Epoch 87/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6595 - accuracy: 0.6111 - val_loss: 0.7544 - val_accuracy: 0.4327\n",
      "Epoch 88/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6728 - accuracy: 0.5741 - val_loss: 0.7656 - val_accuracy: 0.4423\n",
      "Epoch 89/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6870 - accuracy: 0.5825 - val_loss: 0.7590 - val_accuracy: 0.4327\n",
      "Epoch 90/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6978 - accuracy: 0.5606 - val_loss: 0.7550 - val_accuracy: 0.4712\n",
      "Epoch 91/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6848 - accuracy: 0.5774 - val_loss: 0.7646 - val_accuracy: 0.3654\n",
      "Epoch 92/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6677 - accuracy: 0.5993 - val_loss: 0.8029 - val_accuracy: 0.5192\n",
      "Epoch 93/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6655 - accuracy: 0.6027 - val_loss: 0.8080 - val_accuracy: 0.5096\n",
      "Epoch 94/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6632 - accuracy: 0.5758 - val_loss: 0.8167 - val_accuracy: 0.5096\n",
      "Epoch 95/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6507 - accuracy: 0.6263 - val_loss: 0.7453 - val_accuracy: 0.4904\n",
      "Epoch 96/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6462 - accuracy: 0.6263 - val_loss: 0.7346 - val_accuracy: 0.4231\n",
      "Epoch 97/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6499 - accuracy: 0.5943 - val_loss: 0.7249 - val_accuracy: 0.4231\n",
      "Epoch 98/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6456 - accuracy: 0.6027 - val_loss: 0.7403 - val_accuracy: 0.4904\n",
      "Epoch 99/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6399 - accuracy: 0.6313 - val_loss: 0.7421 - val_accuracy: 0.5096\n",
      "Epoch 100/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6397 - accuracy: 0.6313 - val_loss: 0.7377 - val_accuracy: 0.4038\n",
      "Epoch 101/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6297 - accuracy: 0.6347 - val_loss: 0.7384 - val_accuracy: 0.5192\n",
      "Epoch 102/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6340 - accuracy: 0.6431 - val_loss: 0.9707 - val_accuracy: 0.4712\n",
      "Epoch 103/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6675 - accuracy: 0.5976 - val_loss: 0.7607 - val_accuracy: 0.4615\n",
      "Epoch 104/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6577 - accuracy: 0.5960 - val_loss: 0.7558 - val_accuracy: 0.4423\n",
      "Epoch 105/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6729 - accuracy: 0.5539 - val_loss: 0.7507 - val_accuracy: 0.4519\n",
      "Epoch 106/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6701 - accuracy: 0.5892 - val_loss: 0.7547 - val_accuracy: 0.4519\n",
      "Epoch 107/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6734 - accuracy: 0.5404 - val_loss: 0.7743 - val_accuracy: 0.5192\n",
      "Epoch 108/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6497 - accuracy: 0.6212 - val_loss: 0.8508 - val_accuracy: 0.4808\n",
      "Epoch 109/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6539 - accuracy: 0.6145 - val_loss: 0.8270 - val_accuracy: 0.5096\n",
      "Epoch 110/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6589 - accuracy: 0.6279 - val_loss: 0.7805 - val_accuracy: 0.5288\n",
      "Epoch 111/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6673 - accuracy: 0.5875 - val_loss: 0.7245 - val_accuracy: 0.4904\n",
      "Epoch 112/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6451 - accuracy: 0.6195 - val_loss: 0.7238 - val_accuracy: 0.4808\n",
      "Epoch 113/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6415 - accuracy: 0.6094 - val_loss: 0.7316 - val_accuracy: 0.5192\n",
      "Epoch 114/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6559 - accuracy: 0.6027 - val_loss: 0.7987 - val_accuracy: 0.4615\n",
      "Epoch 115/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6664 - accuracy: 0.6061 - val_loss: 0.7750 - val_accuracy: 0.3846\n",
      "Epoch 116/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6506 - accuracy: 0.5791 - val_loss: 0.8163 - val_accuracy: 0.4615\n",
      "Epoch 117/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6553 - accuracy: 0.6195 - val_loss: 0.7410 - val_accuracy: 0.4904\n",
      "Epoch 118/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6395 - accuracy: 0.6313 - val_loss: 0.7376 - val_accuracy: 0.5288\n",
      "Epoch 119/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6407 - accuracy: 0.6246 - val_loss: 0.7285 - val_accuracy: 0.5577\n",
      "Epoch 120/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6404 - accuracy: 0.6380 - val_loss: 0.7643 - val_accuracy: 0.4038\n",
      "Epoch 121/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6276 - accuracy: 0.6465 - val_loss: 0.7593 - val_accuracy: 0.5096\n",
      "Epoch 122/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6364 - accuracy: 0.6364 - val_loss: 0.8141 - val_accuracy: 0.4808\n",
      "Epoch 123/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6504 - accuracy: 0.6027 - val_loss: 0.9187 - val_accuracy: 0.5096\n",
      "Epoch 124/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6383 - accuracy: 0.6364 - val_loss: 0.7370 - val_accuracy: 0.5577\n",
      "Epoch 125/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6384 - accuracy: 0.6263 - val_loss: 0.6957 - val_accuracy: 0.5385\n",
      "Epoch 126/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6462 - accuracy: 0.6229 - val_loss: 0.7091 - val_accuracy: 0.5000\n",
      "Epoch 127/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6494 - accuracy: 0.6414 - val_loss: 0.7205 - val_accuracy: 0.5385\n",
      "Epoch 128/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6518 - accuracy: 0.6229 - val_loss: 0.7543 - val_accuracy: 0.5288\n",
      "Epoch 129/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6363 - accuracy: 0.6246 - val_loss: 0.7264 - val_accuracy: 0.4808\n",
      "Epoch 130/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6306 - accuracy: 0.6549 - val_loss: 0.7827 - val_accuracy: 0.4904\n",
      "Epoch 131/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6459 - accuracy: 0.6094 - val_loss: 0.7754 - val_accuracy: 0.4615\n",
      "Epoch 132/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6519 - accuracy: 0.5960 - val_loss: 0.7614 - val_accuracy: 0.4712\n",
      "Epoch 133/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6577 - accuracy: 0.5842 - val_loss: 0.8387 - val_accuracy: 0.5000\n",
      "Epoch 134/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6472 - accuracy: 0.6380 - val_loss: 0.7327 - val_accuracy: 0.5385\n",
      "Epoch 135/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6305 - accuracy: 0.6330 - val_loss: 0.7626 - val_accuracy: 0.4904\n",
      "Epoch 136/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6286 - accuracy: 0.6448 - val_loss: 0.7461 - val_accuracy: 0.4712\n",
      "Epoch 137/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6399 - accuracy: 0.6229 - val_loss: 0.7972 - val_accuracy: 0.4904\n",
      "Epoch 138/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6510 - accuracy: 0.6111 - val_loss: 0.7873 - val_accuracy: 0.4808\n",
      "Epoch 139/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6285 - accuracy: 0.6397 - val_loss: 0.7170 - val_accuracy: 0.5000\n",
      "Epoch 140/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6284 - accuracy: 0.6465 - val_loss: 0.8053 - val_accuracy: 0.4904\n",
      "Epoch 141/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6493 - accuracy: 0.6431 - val_loss: 0.7562 - val_accuracy: 0.4519\n",
      "Epoch 142/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6358 - accuracy: 0.6263 - val_loss: 0.7719 - val_accuracy: 0.4615\n",
      "Epoch 143/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6289 - accuracy: 0.6296 - val_loss: 0.7374 - val_accuracy: 0.5385\n",
      "Epoch 144/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6167 - accuracy: 0.6515 - val_loss: 0.7074 - val_accuracy: 0.5000\n",
      "Epoch 145/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6363 - accuracy: 0.6515 - val_loss: 0.8404 - val_accuracy: 0.5096\n",
      "Epoch 146/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6280 - accuracy: 0.6347 - val_loss: 0.8105 - val_accuracy: 0.5096\n",
      "Epoch 147/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6268 - accuracy: 0.6465 - val_loss: 0.8565 - val_accuracy: 0.5288\n",
      "Epoch 148/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6622 - accuracy: 0.5926 - val_loss: 0.7250 - val_accuracy: 0.5288\n",
      "Epoch 149/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6328 - accuracy: 0.6599 - val_loss: 0.7524 - val_accuracy: 0.4808\n",
      "Epoch 150/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6244 - accuracy: 0.6414 - val_loss: 0.7265 - val_accuracy: 0.4519\n",
      "Epoch 151/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6203 - accuracy: 0.6229 - val_loss: 0.7244 - val_accuracy: 0.5192\n",
      "Epoch 152/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6369 - accuracy: 0.6229 - val_loss: 0.7434 - val_accuracy: 0.5000\n",
      "Epoch 153/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6328 - accuracy: 0.6246 - val_loss: 0.7451 - val_accuracy: 0.4519\n",
      "Epoch 154/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6169 - accuracy: 0.6414 - val_loss: 0.7656 - val_accuracy: 0.4231\n",
      "Epoch 155/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6529 - accuracy: 0.5993 - val_loss: 0.7875 - val_accuracy: 0.4423\n",
      "Epoch 156/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6438 - accuracy: 0.5791 - val_loss: 0.7309 - val_accuracy: 0.5385\n",
      "Epoch 157/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6289 - accuracy: 0.6347 - val_loss: 0.9544 - val_accuracy: 0.4808\n",
      "Epoch 158/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6227 - accuracy: 0.6178 - val_loss: 0.7279 - val_accuracy: 0.5096\n",
      "Epoch 159/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6345 - accuracy: 0.6347 - val_loss: 0.7193 - val_accuracy: 0.5096\n",
      "Epoch 160/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6155 - accuracy: 0.6717 - val_loss: 0.7317 - val_accuracy: 0.5288\n",
      "Epoch 161/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6069 - accuracy: 0.6448 - val_loss: 0.8144 - val_accuracy: 0.4904\n",
      "Epoch 162/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6326 - accuracy: 0.6279 - val_loss: 0.7750 - val_accuracy: 0.4808\n",
      "Epoch 163/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6256 - accuracy: 0.6313 - val_loss: 0.6846 - val_accuracy: 0.5577\n",
      "Epoch 164/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6250 - accuracy: 0.6347 - val_loss: 0.7729 - val_accuracy: 0.5288\n",
      "Epoch 165/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6235 - accuracy: 0.6498 - val_loss: 0.7210 - val_accuracy: 0.5577\n",
      "Epoch 166/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6263 - accuracy: 0.6684 - val_loss: 0.7346 - val_accuracy: 0.5385\n",
      "Epoch 167/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6262 - accuracy: 0.6313 - val_loss: 0.7494 - val_accuracy: 0.4904\n",
      "Epoch 168/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6381 - accuracy: 0.6347 - val_loss: 0.7396 - val_accuracy: 0.4808\n",
      "Epoch 169/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6641 - accuracy: 0.6061 - val_loss: 0.7660 - val_accuracy: 0.4519\n",
      "Epoch 170/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6417 - accuracy: 0.6279 - val_loss: 0.7205 - val_accuracy: 0.5000\n",
      "Epoch 171/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6138 - accuracy: 0.6448 - val_loss: 0.7740 - val_accuracy: 0.4904\n",
      "Epoch 172/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6133 - accuracy: 0.6397 - val_loss: 0.7149 - val_accuracy: 0.4904\n",
      "Epoch 173/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6214 - accuracy: 0.6330 - val_loss: 0.7532 - val_accuracy: 0.5192\n",
      "Epoch 174/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6282 - accuracy: 0.6633 - val_loss: 0.6977 - val_accuracy: 0.5385\n",
      "Epoch 175/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6540 - accuracy: 0.6145 - val_loss: 0.6986 - val_accuracy: 0.5481\n",
      "Epoch 176/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6608 - accuracy: 0.6279 - val_loss: 0.6983 - val_accuracy: 0.5288\n",
      "Epoch 177/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6434 - accuracy: 0.6246 - val_loss: 0.7486 - val_accuracy: 0.5000\n",
      "Epoch 178/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6538 - accuracy: 0.6061 - val_loss: 0.7068 - val_accuracy: 0.5577\n",
      "Epoch 179/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6454 - accuracy: 0.6195 - val_loss: 0.7285 - val_accuracy: 0.5192\n",
      "Epoch 180/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6425 - accuracy: 0.6364 - val_loss: 0.7111 - val_accuracy: 0.5481\n",
      "Epoch 181/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6173 - accuracy: 0.6448 - val_loss: 0.7714 - val_accuracy: 0.5288\n",
      "Epoch 182/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6286 - accuracy: 0.6347 - val_loss: 0.7373 - val_accuracy: 0.5192\n",
      "Epoch 183/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6406 - accuracy: 0.6465 - val_loss: 0.7159 - val_accuracy: 0.5577\n",
      "Epoch 184/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6758 - accuracy: 0.5673 - val_loss: 0.7597 - val_accuracy: 0.5481\n",
      "Epoch 185/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6780 - accuracy: 0.5976 - val_loss: 0.7013 - val_accuracy: 0.5673\n",
      "Epoch 186/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6582 - accuracy: 0.6111 - val_loss: 0.7053 - val_accuracy: 0.5577\n",
      "Epoch 187/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6411 - accuracy: 0.6465 - val_loss: 0.7123 - val_accuracy: 0.5288\n",
      "Epoch 188/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6373 - accuracy: 0.6397 - val_loss: 0.7115 - val_accuracy: 0.5577\n",
      "Epoch 189/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6315 - accuracy: 0.6364 - val_loss: 0.7230 - val_accuracy: 0.5385\n",
      "Epoch 190/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6281 - accuracy: 0.6279 - val_loss: 0.7575 - val_accuracy: 0.5096\n",
      "Epoch 191/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6291 - accuracy: 0.6380 - val_loss: 0.7675 - val_accuracy: 0.4904\n",
      "Epoch 192/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6200 - accuracy: 0.6465 - val_loss: 0.7388 - val_accuracy: 0.5000\n",
      "Epoch 193/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6470 - accuracy: 0.6145 - val_loss: 0.8120 - val_accuracy: 0.5000\n",
      "Epoch 194/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6488 - accuracy: 0.6162 - val_loss: 0.7641 - val_accuracy: 0.4712\n",
      "Epoch 195/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6165 - accuracy: 0.6532 - val_loss: 0.7390 - val_accuracy: 0.5000\n",
      "Epoch 196/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6360 - accuracy: 0.6313 - val_loss: 0.7297 - val_accuracy: 0.5288\n",
      "Epoch 197/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6293 - accuracy: 0.6481 - val_loss: 0.7142 - val_accuracy: 0.5481\n",
      "Epoch 198/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6416 - accuracy: 0.6397 - val_loss: 0.6958 - val_accuracy: 0.5385\n",
      "Epoch 199/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6341 - accuracy: 0.6263 - val_loss: 0.7907 - val_accuracy: 0.5000\n",
      "Epoch 200/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6288 - accuracy: 0.6246 - val_loss: 0.6983 - val_accuracy: 0.5769\n",
      "Epoch 201/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6307 - accuracy: 0.6246 - val_loss: 0.7355 - val_accuracy: 0.5000\n",
      "Epoch 202/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6196 - accuracy: 0.6448 - val_loss: 0.7276 - val_accuracy: 0.5288\n",
      "Epoch 203/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6357 - accuracy: 0.6330 - val_loss: 0.7674 - val_accuracy: 0.5000\n",
      "Epoch 204/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6434 - accuracy: 0.6044 - val_loss: 0.7453 - val_accuracy: 0.5000\n",
      "Epoch 205/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6201 - accuracy: 0.6296 - val_loss: 0.8106 - val_accuracy: 0.5096\n",
      "Epoch 206/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6166 - accuracy: 0.6684 - val_loss: 0.7518 - val_accuracy: 0.5385\n",
      "Epoch 207/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6393 - accuracy: 0.6246 - val_loss: 0.8385 - val_accuracy: 0.4712\n",
      "Epoch 208/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6396 - accuracy: 0.6162 - val_loss: 0.7474 - val_accuracy: 0.5192\n",
      "Epoch 209/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6338 - accuracy: 0.6279 - val_loss: 0.7308 - val_accuracy: 0.5192\n",
      "Epoch 210/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6242 - accuracy: 0.6330 - val_loss: 0.7356 - val_accuracy: 0.5481\n",
      "Epoch 211/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6196 - accuracy: 0.6397 - val_loss: 0.7476 - val_accuracy: 0.5288\n",
      "Epoch 212/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6191 - accuracy: 0.6566 - val_loss: 0.7492 - val_accuracy: 0.5192\n",
      "Epoch 213/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6155 - accuracy: 0.6566 - val_loss: 0.7597 - val_accuracy: 0.4904\n",
      "Epoch 214/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6074 - accuracy: 0.6582 - val_loss: 0.7370 - val_accuracy: 0.5577\n",
      "Epoch 215/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6222 - accuracy: 0.6397 - val_loss: 0.7493 - val_accuracy: 0.5096\n",
      "Epoch 216/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6095 - accuracy: 0.6431 - val_loss: 0.7439 - val_accuracy: 0.5385\n",
      "Epoch 217/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6088 - accuracy: 0.6364 - val_loss: 0.7309 - val_accuracy: 0.5385\n",
      "Epoch 218/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6203 - accuracy: 0.6599 - val_loss: 0.7307 - val_accuracy: 0.5000\n",
      "Epoch 219/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6191 - accuracy: 0.6431 - val_loss: 0.7968 - val_accuracy: 0.5000\n",
      "Epoch 220/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6073 - accuracy: 0.6650 - val_loss: 0.7477 - val_accuracy: 0.5288\n",
      "Epoch 221/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6119 - accuracy: 0.6481 - val_loss: 0.7577 - val_accuracy: 0.4904\n",
      "Epoch 222/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6163 - accuracy: 0.6330 - val_loss: 0.7356 - val_accuracy: 0.5385\n",
      "Epoch 223/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6193 - accuracy: 0.6684 - val_loss: 0.7444 - val_accuracy: 0.5192\n",
      "Epoch 224/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6279 - accuracy: 0.6263 - val_loss: 0.8017 - val_accuracy: 0.5096\n",
      "Epoch 225/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6321 - accuracy: 0.6448 - val_loss: 0.7406 - val_accuracy: 0.5385\n",
      "Epoch 226/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6195 - accuracy: 0.6465 - val_loss: 0.7030 - val_accuracy: 0.5577\n",
      "Epoch 227/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6208 - accuracy: 0.6431 - val_loss: 0.7643 - val_accuracy: 0.5000\n",
      "Epoch 228/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6357 - accuracy: 0.6229 - val_loss: 0.7196 - val_accuracy: 0.5577\n",
      "Epoch 229/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6576 - accuracy: 0.6061 - val_loss: 0.7040 - val_accuracy: 0.5769\n",
      "Epoch 230/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6471 - accuracy: 0.6111 - val_loss: 0.7164 - val_accuracy: 0.5769\n",
      "Epoch 231/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6454 - accuracy: 0.6229 - val_loss: 0.6983 - val_accuracy: 0.5481\n",
      "Epoch 232/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6426 - accuracy: 0.6330 - val_loss: 0.7289 - val_accuracy: 0.5385\n",
      "Epoch 233/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6399 - accuracy: 0.6296 - val_loss: 0.7128 - val_accuracy: 0.5481\n",
      "Epoch 234/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6619 - accuracy: 0.5758 - val_loss: 0.7253 - val_accuracy: 0.5769\n",
      "Epoch 235/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6589 - accuracy: 0.6296 - val_loss: 0.7098 - val_accuracy: 0.4327\n",
      "Epoch 236/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6565 - accuracy: 0.6061 - val_loss: 0.7178 - val_accuracy: 0.5385\n",
      "Epoch 237/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6443 - accuracy: 0.6330 - val_loss: 0.7282 - val_accuracy: 0.5096\n",
      "Epoch 238/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6578 - accuracy: 0.5943 - val_loss: 0.7061 - val_accuracy: 0.5673\n",
      "Epoch 239/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6586 - accuracy: 0.6162 - val_loss: 0.7306 - val_accuracy: 0.5673\n",
      "Epoch 240/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6664 - accuracy: 0.6128 - val_loss: 0.7173 - val_accuracy: 0.3942\n",
      "Epoch 241/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6595 - accuracy: 0.6061 - val_loss: 0.7030 - val_accuracy: 0.5481\n",
      "Epoch 242/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6570 - accuracy: 0.5976 - val_loss: 0.7274 - val_accuracy: 0.5673\n",
      "Epoch 243/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6613 - accuracy: 0.6094 - val_loss: 0.7222 - val_accuracy: 0.4808\n",
      "Epoch 244/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6458 - accuracy: 0.6128 - val_loss: 0.7710 - val_accuracy: 0.4904\n",
      "Epoch 245/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6264 - accuracy: 0.6515 - val_loss: 0.8920 - val_accuracy: 0.4615\n",
      "Epoch 246/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6043 - accuracy: 0.6734 - val_loss: 0.7538 - val_accuracy: 0.5192\n",
      "Epoch 247/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6253 - accuracy: 0.6431 - val_loss: 0.7752 - val_accuracy: 0.4904\n",
      "Epoch 248/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6106 - accuracy: 0.6481 - val_loss: 0.7739 - val_accuracy: 0.5000\n",
      "Epoch 249/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6170 - accuracy: 0.6667 - val_loss: 0.7668 - val_accuracy: 0.5288\n",
      "Epoch 250/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6014 - accuracy: 0.6532 - val_loss: 0.8066 - val_accuracy: 0.5288\n",
      "Epoch 251/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6070 - accuracy: 0.6667 - val_loss: 0.7854 - val_accuracy: 0.5288\n",
      "Epoch 252/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5996 - accuracy: 0.6886 - val_loss: 0.7863 - val_accuracy: 0.5192\n",
      "Epoch 253/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6113 - accuracy: 0.6599 - val_loss: 0.7903 - val_accuracy: 0.5096\n",
      "Epoch 254/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6211 - accuracy: 0.6481 - val_loss: 0.7595 - val_accuracy: 0.5481\n",
      "Epoch 255/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6124 - accuracy: 0.6599 - val_loss: 0.7321 - val_accuracy: 0.5288\n",
      "Epoch 256/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5882 - accuracy: 0.6684 - val_loss: 0.7562 - val_accuracy: 0.5096\n",
      "Epoch 257/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5931 - accuracy: 0.6582 - val_loss: 0.7562 - val_accuracy: 0.5000\n",
      "Epoch 258/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5882 - accuracy: 0.6684 - val_loss: 0.7751 - val_accuracy: 0.5192\n",
      "Epoch 259/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6039 - accuracy: 0.6566 - val_loss: 0.7347 - val_accuracy: 0.5385\n",
      "Epoch 260/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5912 - accuracy: 0.6835 - val_loss: 0.7895 - val_accuracy: 0.5288\n",
      "Epoch 261/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5932 - accuracy: 0.6532 - val_loss: 0.7934 - val_accuracy: 0.5192\n",
      "Epoch 262/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6016 - accuracy: 0.6751 - val_loss: 0.7826 - val_accuracy: 0.5192\n",
      "Epoch 263/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5942 - accuracy: 0.6768 - val_loss: 0.7854 - val_accuracy: 0.5000\n",
      "Epoch 264/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5928 - accuracy: 0.6667 - val_loss: 0.7628 - val_accuracy: 0.5481\n",
      "Epoch 265/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5989 - accuracy: 0.6717 - val_loss: 0.7616 - val_accuracy: 0.5481\n",
      "Epoch 266/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5877 - accuracy: 0.6751 - val_loss: 0.7604 - val_accuracy: 0.4904\n",
      "Epoch 267/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6238 - accuracy: 0.6667 - val_loss: 0.7989 - val_accuracy: 0.5000\n",
      "Epoch 268/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5884 - accuracy: 0.6566 - val_loss: 0.7664 - val_accuracy: 0.5096\n",
      "Epoch 269/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6084 - accuracy: 0.6616 - val_loss: 0.7469 - val_accuracy: 0.5192\n",
      "Epoch 270/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5968 - accuracy: 0.6599 - val_loss: 0.7994 - val_accuracy: 0.5000\n",
      "Epoch 271/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6124 - accuracy: 0.6751 - val_loss: 0.7270 - val_accuracy: 0.4808\n",
      "Epoch 272/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5990 - accuracy: 0.6684 - val_loss: 0.7563 - val_accuracy: 0.5192\n",
      "Epoch 273/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6034 - accuracy: 0.6667 - val_loss: 0.8058 - val_accuracy: 0.5192\n",
      "Epoch 274/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5970 - accuracy: 0.6566 - val_loss: 0.7963 - val_accuracy: 0.4904\n",
      "Epoch 275/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6023 - accuracy: 0.6734 - val_loss: 0.7250 - val_accuracy: 0.5192\n",
      "Epoch 276/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6006 - accuracy: 0.6599 - val_loss: 0.7577 - val_accuracy: 0.5096\n",
      "Epoch 277/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6176 - accuracy: 0.6465 - val_loss: 0.7066 - val_accuracy: 0.5673\n",
      "Epoch 278/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6135 - accuracy: 0.6549 - val_loss: 0.7372 - val_accuracy: 0.5288\n",
      "Epoch 279/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5890 - accuracy: 0.6835 - val_loss: 0.7937 - val_accuracy: 0.5385\n",
      "Epoch 280/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5974 - accuracy: 0.6599 - val_loss: 0.7889 - val_accuracy: 0.5288\n",
      "Epoch 281/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5924 - accuracy: 0.6599 - val_loss: 0.7900 - val_accuracy: 0.5096\n",
      "Epoch 282/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5995 - accuracy: 0.6481 - val_loss: 0.8046 - val_accuracy: 0.5192\n",
      "Epoch 283/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6074 - accuracy: 0.6599 - val_loss: 0.7647 - val_accuracy: 0.5096\n",
      "Epoch 284/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6002 - accuracy: 0.6667 - val_loss: 0.7769 - val_accuracy: 0.5288\n",
      "Epoch 285/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5987 - accuracy: 0.6633 - val_loss: 0.8031 - val_accuracy: 0.5288\n",
      "Epoch 286/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5962 - accuracy: 0.6700 - val_loss: 0.7550 - val_accuracy: 0.5000\n",
      "Epoch 287/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6010 - accuracy: 0.6650 - val_loss: 0.8270 - val_accuracy: 0.5096\n",
      "Epoch 288/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5991 - accuracy: 0.6582 - val_loss: 0.7419 - val_accuracy: 0.5481\n",
      "Epoch 289/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6111 - accuracy: 0.6515 - val_loss: 0.7445 - val_accuracy: 0.5385\n",
      "Epoch 290/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6235 - accuracy: 0.6481 - val_loss: 0.7208 - val_accuracy: 0.5288\n",
      "Epoch 291/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6504 - accuracy: 0.6162 - val_loss: 0.7034 - val_accuracy: 0.5288\n",
      "Epoch 292/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6503 - accuracy: 0.6061 - val_loss: 0.7150 - val_accuracy: 0.5288\n",
      "Epoch 293/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6007 - accuracy: 0.6566 - val_loss: 0.7298 - val_accuracy: 0.5385\n",
      "Epoch 294/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6099 - accuracy: 0.6566 - val_loss: 0.7485 - val_accuracy: 0.5481\n",
      "Epoch 295/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5784 - accuracy: 0.6953 - val_loss: 0.7833 - val_accuracy: 0.4808\n",
      "Epoch 296/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6003 - accuracy: 0.6616 - val_loss: 0.7550 - val_accuracy: 0.5385\n",
      "Epoch 297/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6028 - accuracy: 0.6785 - val_loss: 0.7751 - val_accuracy: 0.5192\n",
      "Epoch 298/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5788 - accuracy: 0.6751 - val_loss: 0.7770 - val_accuracy: 0.5000\n",
      "Epoch 299/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6015 - accuracy: 0.6835 - val_loss: 0.7679 - val_accuracy: 0.4904\n",
      "Epoch 300/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5984 - accuracy: 0.6700 - val_loss: 0.7948 - val_accuracy: 0.5000\n",
      "Epoch 301/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6027 - accuracy: 0.6498 - val_loss: 0.8661 - val_accuracy: 0.5000\n",
      "Epoch 302/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5962 - accuracy: 0.6869 - val_loss: 0.9288 - val_accuracy: 0.4615\n",
      "Epoch 303/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.5913 - accuracy: 0.6768 - val_loss: 0.7682 - val_accuracy: 0.5288\n",
      "Epoch 304/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6060 - accuracy: 0.6566 - val_loss: 0.7862 - val_accuracy: 0.5096\n",
      "Epoch 305/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5998 - accuracy: 0.6667 - val_loss: 0.7597 - val_accuracy: 0.5096\n",
      "Epoch 306/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5983 - accuracy: 0.6566 - val_loss: 0.7696 - val_accuracy: 0.5192\n",
      "Epoch 307/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6104 - accuracy: 0.6229 - val_loss: 0.7771 - val_accuracy: 0.5288\n",
      "Epoch 308/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6000 - accuracy: 0.6481 - val_loss: 0.7840 - val_accuracy: 0.5096\n",
      "Epoch 309/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5998 - accuracy: 0.6549 - val_loss: 0.7758 - val_accuracy: 0.4808\n",
      "Epoch 310/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6286 - accuracy: 0.6515 - val_loss: 0.7769 - val_accuracy: 0.4615\n",
      "Epoch 311/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6070 - accuracy: 0.6515 - val_loss: 0.7832 - val_accuracy: 0.5000\n",
      "Epoch 312/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5944 - accuracy: 0.6751 - val_loss: 0.7892 - val_accuracy: 0.5000\n",
      "Epoch 313/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6105 - accuracy: 0.6582 - val_loss: 0.7743 - val_accuracy: 0.4904\n",
      "Epoch 314/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5865 - accuracy: 0.6582 - val_loss: 0.7530 - val_accuracy: 0.5096\n",
      "Epoch 315/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6478 - accuracy: 0.6296 - val_loss: 0.7413 - val_accuracy: 0.5385\n",
      "Epoch 316/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6056 - accuracy: 0.6734 - val_loss: 0.8247 - val_accuracy: 0.5288\n",
      "Epoch 317/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6175 - accuracy: 0.6397 - val_loss: 0.8024 - val_accuracy: 0.5192\n",
      "Epoch 318/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6191 - accuracy: 0.6448 - val_loss: 0.8060 - val_accuracy: 0.5192\n",
      "Epoch 319/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6055 - accuracy: 0.6566 - val_loss: 0.7784 - val_accuracy: 0.5385\n",
      "Epoch 320/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6118 - accuracy: 0.6380 - val_loss: 0.7958 - val_accuracy: 0.5192\n",
      "Epoch 321/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6138 - accuracy: 0.6616 - val_loss: 0.7166 - val_accuracy: 0.5481\n",
      "Epoch 322/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6247 - accuracy: 0.6481 - val_loss: 0.7272 - val_accuracy: 0.5385\n",
      "Epoch 323/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6225 - accuracy: 0.6481 - val_loss: 0.7550 - val_accuracy: 0.5096\n",
      "Epoch 324/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6222 - accuracy: 0.6532 - val_loss: 0.7110 - val_accuracy: 0.5481\n",
      "Epoch 325/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6140 - accuracy: 0.6616 - val_loss: 0.7347 - val_accuracy: 0.5577\n",
      "Epoch 326/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6104 - accuracy: 0.6414 - val_loss: 0.8424 - val_accuracy: 0.4808\n",
      "Epoch 327/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6175 - accuracy: 0.6263 - val_loss: 0.8355 - val_accuracy: 0.4904\n",
      "Epoch 328/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5934 - accuracy: 0.6566 - val_loss: 0.7827 - val_accuracy: 0.4808\n",
      "Epoch 329/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6327 - accuracy: 0.6397 - val_loss: 0.7894 - val_accuracy: 0.5481\n",
      "Epoch 330/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6109 - accuracy: 0.6330 - val_loss: 0.7584 - val_accuracy: 0.5000\n",
      "Epoch 331/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6075 - accuracy: 0.6616 - val_loss: 0.7392 - val_accuracy: 0.5192\n",
      "Epoch 332/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6259 - accuracy: 0.6448 - val_loss: 0.7297 - val_accuracy: 0.5385\n",
      "Epoch 333/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6259 - accuracy: 0.6364 - val_loss: 0.7958 - val_accuracy: 0.5288\n",
      "Epoch 334/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6103 - accuracy: 0.6599 - val_loss: 0.7658 - val_accuracy: 0.5288\n",
      "Epoch 335/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5827 - accuracy: 0.6532 - val_loss: 0.8109 - val_accuracy: 0.4904\n",
      "Epoch 336/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6127 - accuracy: 0.6616 - val_loss: 0.7619 - val_accuracy: 0.4904\n",
      "Epoch 337/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.5993 - accuracy: 0.6633 - val_loss: 0.7542 - val_accuracy: 0.5288\n",
      "Epoch 338/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6168 - accuracy: 0.6515 - val_loss: 0.7587 - val_accuracy: 0.5769\n",
      "Epoch 339/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5968 - accuracy: 0.6852 - val_loss: 0.7734 - val_accuracy: 0.5000\n",
      "Epoch 340/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5898 - accuracy: 0.6785 - val_loss: 0.7522 - val_accuracy: 0.5192\n",
      "Epoch 341/1000\n",
      "594/594 [==============================] - 2s 4ms/step - loss: 0.6042 - accuracy: 0.6582 - val_loss: 0.7659 - val_accuracy: 0.5096\n",
      "Epoch 342/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5949 - accuracy: 0.6835 - val_loss: 0.9460 - val_accuracy: 0.4808\n",
      "Epoch 343/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6059 - accuracy: 0.6734 - val_loss: 0.7487 - val_accuracy: 0.5000\n",
      "Epoch 344/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6005 - accuracy: 0.6481 - val_loss: 0.8334 - val_accuracy: 0.4808\n",
      "Epoch 345/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6117 - accuracy: 0.6818 - val_loss: 0.7570 - val_accuracy: 0.5577\n",
      "Epoch 346/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5841 - accuracy: 0.6818 - val_loss: 0.7720 - val_accuracy: 0.5288\n",
      "Epoch 347/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5920 - accuracy: 0.6751 - val_loss: 0.8745 - val_accuracy: 0.4904\n",
      "Epoch 348/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5852 - accuracy: 0.6734 - val_loss: 0.7336 - val_accuracy: 0.5288\n",
      "Epoch 349/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6186 - accuracy: 0.6566 - val_loss: 0.8241 - val_accuracy: 0.4519\n",
      "Epoch 350/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5906 - accuracy: 0.6751 - val_loss: 0.7757 - val_accuracy: 0.5000\n",
      "Epoch 351/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6100 - accuracy: 0.6481 - val_loss: 0.7985 - val_accuracy: 0.5096\n",
      "Epoch 352/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5979 - accuracy: 0.6566 - val_loss: 0.7828 - val_accuracy: 0.5481\n",
      "Epoch 353/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5914 - accuracy: 0.6616 - val_loss: 0.8133 - val_accuracy: 0.5096\n",
      "Epoch 354/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5850 - accuracy: 0.6667 - val_loss: 0.7888 - val_accuracy: 0.5000\n",
      "Epoch 355/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5895 - accuracy: 0.6684 - val_loss: 0.8352 - val_accuracy: 0.5192\n",
      "Epoch 356/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.7056 - accuracy: 0.5657 - val_loss: 0.8036 - val_accuracy: 0.4615\n",
      "Epoch 357/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6622 - accuracy: 0.6347 - val_loss: 0.8083 - val_accuracy: 0.4519\n",
      "Epoch 358/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6702 - accuracy: 0.6178 - val_loss: 0.7761 - val_accuracy: 0.5000\n",
      "Epoch 359/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6529 - accuracy: 0.6010 - val_loss: 0.7896 - val_accuracy: 0.4615\n",
      "Epoch 360/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6626 - accuracy: 0.6094 - val_loss: 0.8335 - val_accuracy: 0.4904\n",
      "Epoch 361/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6706 - accuracy: 0.5455 - val_loss: 0.8085 - val_accuracy: 0.5192\n",
      "Epoch 362/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6744 - accuracy: 0.6111 - val_loss: 0.7850 - val_accuracy: 0.4423\n",
      "Epoch 363/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6473 - accuracy: 0.6044 - val_loss: 0.7470 - val_accuracy: 0.5192\n",
      "Epoch 364/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6149 - accuracy: 0.6566 - val_loss: 0.7181 - val_accuracy: 0.5096\n",
      "Epoch 365/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6035 - accuracy: 0.6599 - val_loss: 0.7256 - val_accuracy: 0.5385\n",
      "Epoch 366/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6092 - accuracy: 0.6582 - val_loss: 0.7582 - val_accuracy: 0.5673\n",
      "Epoch 367/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6266 - accuracy: 0.6515 - val_loss: 0.7524 - val_accuracy: 0.5096\n",
      "Epoch 368/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5980 - accuracy: 0.6582 - val_loss: 0.7469 - val_accuracy: 0.5192\n",
      "Epoch 369/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6079 - accuracy: 0.6498 - val_loss: 0.7686 - val_accuracy: 0.5096\n",
      "Epoch 370/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6014 - accuracy: 0.6785 - val_loss: 0.8595 - val_accuracy: 0.5000\n",
      "Epoch 371/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5897 - accuracy: 0.6768 - val_loss: 0.7667 - val_accuracy: 0.5192\n",
      "Epoch 372/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5914 - accuracy: 0.6835 - val_loss: 0.8388 - val_accuracy: 0.4904\n",
      "Epoch 373/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6139 - accuracy: 0.6347 - val_loss: 0.7804 - val_accuracy: 0.5385\n",
      "Epoch 374/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5960 - accuracy: 0.6717 - val_loss: 0.7535 - val_accuracy: 0.5000\n",
      "Epoch 375/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6251 - accuracy: 0.6515 - val_loss: 0.8351 - val_accuracy: 0.4904\n",
      "Epoch 376/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6154 - accuracy: 0.6650 - val_loss: 0.7685 - val_accuracy: 0.5288\n",
      "Epoch 377/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6091 - accuracy: 0.6717 - val_loss: 0.8464 - val_accuracy: 0.5000\n",
      "Epoch 378/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6445 - accuracy: 0.6380 - val_loss: 0.7313 - val_accuracy: 0.5481\n",
      "Epoch 379/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6276 - accuracy: 0.6566 - val_loss: 0.7212 - val_accuracy: 0.5288\n",
      "Epoch 380/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6345 - accuracy: 0.6094 - val_loss: 0.7524 - val_accuracy: 0.5577\n",
      "Epoch 381/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6398 - accuracy: 0.6313 - val_loss: 0.7577 - val_accuracy: 0.5096\n",
      "Epoch 382/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6216 - accuracy: 0.6549 - val_loss: 0.7848 - val_accuracy: 0.5000\n",
      "Epoch 383/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6158 - accuracy: 0.6582 - val_loss: 0.7358 - val_accuracy: 0.5481\n",
      "Epoch 384/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5931 - accuracy: 0.6801 - val_loss: 0.7811 - val_accuracy: 0.5577\n",
      "Epoch 385/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6138 - accuracy: 0.6616 - val_loss: 0.7702 - val_accuracy: 0.5481\n",
      "Epoch 386/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6099 - accuracy: 0.6650 - val_loss: 0.7262 - val_accuracy: 0.5673\n",
      "Epoch 387/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5948 - accuracy: 0.6835 - val_loss: 0.7327 - val_accuracy: 0.5481\n",
      "Epoch 388/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5975 - accuracy: 0.6801 - val_loss: 0.7648 - val_accuracy: 0.5288\n",
      "Epoch 389/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5955 - accuracy: 0.6582 - val_loss: 0.7674 - val_accuracy: 0.5288\n",
      "Epoch 390/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6099 - accuracy: 0.6532 - val_loss: 0.7468 - val_accuracy: 0.5385\n",
      "Epoch 391/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6146 - accuracy: 0.6498 - val_loss: 0.8240 - val_accuracy: 0.4808\n",
      "Epoch 392/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6099 - accuracy: 0.6465 - val_loss: 0.8293 - val_accuracy: 0.4904\n",
      "Epoch 393/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6080 - accuracy: 0.6633 - val_loss: 0.8413 - val_accuracy: 0.4904\n",
      "Epoch 394/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5916 - accuracy: 0.6684 - val_loss: 0.7370 - val_accuracy: 0.5192\n",
      "Epoch 395/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6145 - accuracy: 0.6364 - val_loss: 0.7687 - val_accuracy: 0.5288\n",
      "Epoch 396/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5987 - accuracy: 0.6532 - val_loss: 0.7608 - val_accuracy: 0.5673\n",
      "Epoch 397/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5885 - accuracy: 0.6700 - val_loss: 0.7830 - val_accuracy: 0.5288\n",
      "Epoch 398/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5853 - accuracy: 0.6768 - val_loss: 0.7786 - val_accuracy: 0.5192\n",
      "Epoch 399/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5903 - accuracy: 0.6599 - val_loss: 0.7718 - val_accuracy: 0.5096\n",
      "Epoch 400/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5986 - accuracy: 0.6582 - val_loss: 0.7446 - val_accuracy: 0.5385\n",
      "Epoch 401/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5970 - accuracy: 0.6465 - val_loss: 0.8087 - val_accuracy: 0.5385\n",
      "Epoch 402/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5914 - accuracy: 0.6515 - val_loss: 0.7742 - val_accuracy: 0.4904\n",
      "Epoch 403/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5985 - accuracy: 0.6650 - val_loss: 0.7815 - val_accuracy: 0.4808\n",
      "Epoch 404/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5826 - accuracy: 0.6633 - val_loss: 0.7892 - val_accuracy: 0.4904\n",
      "Epoch 405/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6147 - accuracy: 0.6246 - val_loss: 0.7783 - val_accuracy: 0.5192\n",
      "Epoch 406/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5968 - accuracy: 0.6700 - val_loss: 0.7523 - val_accuracy: 0.5192\n",
      "Epoch 407/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5946 - accuracy: 0.6633 - val_loss: 0.7790 - val_accuracy: 0.5288\n",
      "Epoch 408/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5831 - accuracy: 0.6801 - val_loss: 0.7959 - val_accuracy: 0.5192\n",
      "Epoch 409/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5826 - accuracy: 0.6768 - val_loss: 0.8303 - val_accuracy: 0.5288\n",
      "Epoch 410/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5930 - accuracy: 0.6700 - val_loss: 0.8191 - val_accuracy: 0.5192\n",
      "Epoch 411/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6305 - accuracy: 0.6313 - val_loss: 0.7162 - val_accuracy: 0.5769\n",
      "Epoch 412/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6495 - accuracy: 0.6229 - val_loss: 0.7197 - val_accuracy: 0.5769\n",
      "Epoch 413/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6293 - accuracy: 0.6414 - val_loss: 0.7915 - val_accuracy: 0.5096\n",
      "Epoch 414/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5983 - accuracy: 0.6852 - val_loss: 0.7666 - val_accuracy: 0.5385\n",
      "Epoch 415/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5886 - accuracy: 0.6785 - val_loss: 0.7647 - val_accuracy: 0.5096\n",
      "Epoch 416/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5955 - accuracy: 0.6650 - val_loss: 0.8341 - val_accuracy: 0.4712\n",
      "Epoch 417/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6073 - accuracy: 0.6313 - val_loss: 0.7593 - val_accuracy: 0.4712\n",
      "Epoch 418/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5912 - accuracy: 0.6700 - val_loss: 0.7307 - val_accuracy: 0.5769\n",
      "Epoch 419/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5841 - accuracy: 0.6734 - val_loss: 0.7263 - val_accuracy: 0.5385\n",
      "Epoch 420/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5860 - accuracy: 0.6768 - val_loss: 0.7534 - val_accuracy: 0.5385\n",
      "Epoch 421/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6301 - accuracy: 0.6380 - val_loss: 0.7585 - val_accuracy: 0.5000\n",
      "Epoch 422/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6398 - accuracy: 0.6448 - val_loss: 0.7826 - val_accuracy: 0.5096\n",
      "Epoch 423/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5978 - accuracy: 0.6566 - val_loss: 0.7354 - val_accuracy: 0.5481\n",
      "Epoch 424/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6559 - accuracy: 0.6380 - val_loss: 0.8202 - val_accuracy: 0.5096\n",
      "Epoch 425/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6880 - accuracy: 0.5976 - val_loss: 0.8318 - val_accuracy: 0.5000\n",
      "Epoch 426/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6724 - accuracy: 0.6296 - val_loss: 0.8166 - val_accuracy: 0.5000\n",
      "Epoch 427/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6764 - accuracy: 0.6195 - val_loss: 0.7855 - val_accuracy: 0.4423\n",
      "Epoch 428/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6792 - accuracy: 0.6111 - val_loss: 0.7814 - val_accuracy: 0.5000\n",
      "Epoch 429/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6775 - accuracy: 0.6077 - val_loss: 0.8431 - val_accuracy: 0.4808\n",
      "Epoch 430/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6466 - accuracy: 0.6481 - val_loss: 0.7683 - val_accuracy: 0.4808\n",
      "Epoch 431/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6766 - accuracy: 0.6094 - val_loss: 0.7707 - val_accuracy: 0.5577\n",
      "Epoch 432/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6095 - accuracy: 0.6700 - val_loss: 0.7526 - val_accuracy: 0.4904\n",
      "Epoch 433/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6084 - accuracy: 0.6801 - val_loss: 0.7471 - val_accuracy: 0.5385\n",
      "Epoch 434/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6236 - accuracy: 0.6582 - val_loss: 0.8049 - val_accuracy: 0.4712\n",
      "Epoch 435/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6581 - accuracy: 0.6094 - val_loss: 0.7899 - val_accuracy: 0.4712\n",
      "Epoch 436/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6049 - accuracy: 0.6616 - val_loss: 0.7605 - val_accuracy: 0.5385\n",
      "Epoch 437/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6092 - accuracy: 0.6700 - val_loss: 0.8783 - val_accuracy: 0.5096\n",
      "Epoch 438/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6151 - accuracy: 0.6566 - val_loss: 0.7619 - val_accuracy: 0.4904\n",
      "Epoch 439/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6070 - accuracy: 0.6549 - val_loss: 0.7709 - val_accuracy: 0.5577\n",
      "Epoch 440/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6172 - accuracy: 0.6465 - val_loss: 0.7988 - val_accuracy: 0.5673\n",
      "Epoch 441/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6267 - accuracy: 0.6397 - val_loss: 0.7189 - val_accuracy: 0.5769\n",
      "Epoch 442/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5910 - accuracy: 0.6785 - val_loss: 0.7898 - val_accuracy: 0.4808\n",
      "Epoch 443/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6027 - accuracy: 0.6481 - val_loss: 0.8209 - val_accuracy: 0.5096\n",
      "Epoch 444/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5780 - accuracy: 0.7037 - val_loss: 0.7249 - val_accuracy: 0.5192\n",
      "Epoch 445/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6095 - accuracy: 0.6498 - val_loss: 0.7475 - val_accuracy: 0.5192\n",
      "Epoch 446/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6220 - accuracy: 0.6599 - val_loss: 0.7281 - val_accuracy: 0.5865\n",
      "Epoch 447/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6180 - accuracy: 0.6734 - val_loss: 0.7607 - val_accuracy: 0.5000\n",
      "Epoch 448/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5966 - accuracy: 0.6684 - val_loss: 0.7488 - val_accuracy: 0.4904\n",
      "Epoch 449/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6074 - accuracy: 0.6717 - val_loss: 0.7755 - val_accuracy: 0.5288\n",
      "Epoch 450/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6011 - accuracy: 0.6667 - val_loss: 0.7705 - val_accuracy: 0.5096\n",
      "Epoch 451/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5967 - accuracy: 0.6869 - val_loss: 0.7589 - val_accuracy: 0.5096\n",
      "Epoch 452/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5967 - accuracy: 0.6734 - val_loss: 0.8356 - val_accuracy: 0.4808\n",
      "Epoch 453/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5712 - accuracy: 0.6886 - val_loss: 0.7814 - val_accuracy: 0.5000\n",
      "Epoch 454/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5900 - accuracy: 0.6768 - val_loss: 0.7653 - val_accuracy: 0.5192\n",
      "Epoch 455/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6326 - accuracy: 0.6111 - val_loss: 0.7402 - val_accuracy: 0.5096\n",
      "Epoch 456/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6315 - accuracy: 0.6498 - val_loss: 0.7744 - val_accuracy: 0.5192\n",
      "Epoch 457/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6014 - accuracy: 0.6801 - val_loss: 0.7390 - val_accuracy: 0.5192\n",
      "Epoch 458/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6051 - accuracy: 0.6599 - val_loss: 0.7779 - val_accuracy: 0.5192\n",
      "Epoch 459/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5825 - accuracy: 0.6835 - val_loss: 0.7744 - val_accuracy: 0.5577\n",
      "Epoch 460/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6012 - accuracy: 0.6549 - val_loss: 0.7605 - val_accuracy: 0.5385\n",
      "Epoch 461/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6076 - accuracy: 0.6751 - val_loss: 0.7609 - val_accuracy: 0.5192\n",
      "Epoch 462/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5799 - accuracy: 0.6684 - val_loss: 0.7645 - val_accuracy: 0.5000\n",
      "Epoch 463/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6089 - accuracy: 0.6599 - val_loss: 0.7754 - val_accuracy: 0.4904\n",
      "Epoch 464/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6390 - accuracy: 0.6296 - val_loss: 0.7481 - val_accuracy: 0.5192\n",
      "Epoch 465/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6104 - accuracy: 0.6667 - val_loss: 0.7794 - val_accuracy: 0.5481\n",
      "Epoch 466/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6131 - accuracy: 0.6498 - val_loss: 0.7917 - val_accuracy: 0.5000\n",
      "Epoch 467/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6008 - accuracy: 0.6465 - val_loss: 0.7564 - val_accuracy: 0.5288\n",
      "Epoch 468/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5830 - accuracy: 0.6717 - val_loss: 0.8314 - val_accuracy: 0.5000\n",
      "Epoch 469/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6155 - accuracy: 0.6700 - val_loss: 0.7929 - val_accuracy: 0.4712\n",
      "Epoch 470/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6346 - accuracy: 0.6465 - val_loss: 0.7224 - val_accuracy: 0.5288\n",
      "Epoch 471/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5949 - accuracy: 0.6616 - val_loss: 0.7731 - val_accuracy: 0.5000\n",
      "Epoch 472/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5721 - accuracy: 0.6751 - val_loss: 0.8018 - val_accuracy: 0.5385\n",
      "Epoch 473/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5774 - accuracy: 0.6869 - val_loss: 0.7394 - val_accuracy: 0.5577\n",
      "Epoch 474/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6047 - accuracy: 0.6785 - val_loss: 0.7425 - val_accuracy: 0.5673\n",
      "Epoch 475/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6089 - accuracy: 0.6532 - val_loss: 0.7997 - val_accuracy: 0.4904\n",
      "Epoch 476/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6731 - accuracy: 0.6380 - val_loss: 0.8010 - val_accuracy: 0.5288\n",
      "Epoch 477/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6881 - accuracy: 0.5926 - val_loss: 0.7754 - val_accuracy: 0.4808\n",
      "Epoch 478/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6637 - accuracy: 0.6178 - val_loss: 0.7709 - val_accuracy: 0.5096\n",
      "Epoch 479/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6747 - accuracy: 0.6010 - val_loss: 0.8115 - val_accuracy: 0.5288\n",
      "Epoch 480/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6977 - accuracy: 0.5623 - val_loss: 0.7194 - val_accuracy: 0.4519\n",
      "Epoch 481/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6872 - accuracy: 0.5572 - val_loss: 0.7246 - val_accuracy: 0.5096\n",
      "Epoch 482/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6800 - accuracy: 0.5471 - val_loss: 0.7618 - val_accuracy: 0.5000\n",
      "Epoch 483/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6904 - accuracy: 0.5657 - val_loss: 0.7584 - val_accuracy: 0.4808\n",
      "Epoch 484/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6782 - accuracy: 0.5488 - val_loss: 0.7474 - val_accuracy: 0.5192\n",
      "Epoch 485/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6808 - accuracy: 0.5135 - val_loss: 0.7345 - val_accuracy: 0.4904\n",
      "Epoch 486/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6727 - accuracy: 0.5960 - val_loss: 0.7527 - val_accuracy: 0.5096\n",
      "Epoch 487/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6739 - accuracy: 0.5724 - val_loss: 0.7623 - val_accuracy: 0.4712\n",
      "Epoch 488/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6907 - accuracy: 0.5505 - val_loss: 0.7654 - val_accuracy: 0.4519\n",
      "Epoch 489/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6888 - accuracy: 0.5539 - val_loss: 0.7563 - val_accuracy: 0.4423\n",
      "Epoch 490/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6600 - accuracy: 0.5825 - val_loss: 0.7372 - val_accuracy: 0.5096\n",
      "Epoch 491/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.7040 - accuracy: 0.5690 - val_loss: 0.7520 - val_accuracy: 0.4808\n",
      "Epoch 492/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6856 - accuracy: 0.5741 - val_loss: 0.7528 - val_accuracy: 0.4615\n",
      "Epoch 493/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6742 - accuracy: 0.5387 - val_loss: 0.7486 - val_accuracy: 0.4615\n",
      "Epoch 494/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6745 - accuracy: 0.5657 - val_loss: 0.7598 - val_accuracy: 0.5096\n",
      "Epoch 495/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6674 - accuracy: 0.5926 - val_loss: 0.7452 - val_accuracy: 0.4808\n",
      "Epoch 496/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6573 - accuracy: 0.6044 - val_loss: 0.8280 - val_accuracy: 0.5481\n",
      "Epoch 497/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6744 - accuracy: 0.6044 - val_loss: 0.8285 - val_accuracy: 0.5000\n",
      "Epoch 498/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6290 - accuracy: 0.6566 - val_loss: 0.7661 - val_accuracy: 0.5865\n",
      "Epoch 499/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6499 - accuracy: 0.6532 - val_loss: 0.7779 - val_accuracy: 0.5962\n",
      "Epoch 500/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6293 - accuracy: 0.6397 - val_loss: 0.7572 - val_accuracy: 0.5000\n",
      "Epoch 501/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6472 - accuracy: 0.6397 - val_loss: 0.7399 - val_accuracy: 0.5096\n",
      "Epoch 502/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6287 - accuracy: 0.6414 - val_loss: 0.7670 - val_accuracy: 0.5481\n",
      "Epoch 503/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6204 - accuracy: 0.6397 - val_loss: 0.7443 - val_accuracy: 0.5385\n",
      "Epoch 504/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6233 - accuracy: 0.6599 - val_loss: 0.7358 - val_accuracy: 0.5673\n",
      "Epoch 505/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5958 - accuracy: 0.6751 - val_loss: 0.9031 - val_accuracy: 0.5000\n",
      "Epoch 506/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5842 - accuracy: 0.6835 - val_loss: 0.7532 - val_accuracy: 0.5096\n",
      "Epoch 507/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6262 - accuracy: 0.6431 - val_loss: 0.7949 - val_accuracy: 0.5192\n",
      "Epoch 508/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6311 - accuracy: 0.6263 - val_loss: 0.7702 - val_accuracy: 0.5096\n",
      "Epoch 509/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6073 - accuracy: 0.6667 - val_loss: 0.7527 - val_accuracy: 0.5673\n",
      "Epoch 510/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6274 - accuracy: 0.6212 - val_loss: 0.7235 - val_accuracy: 0.5288\n",
      "Epoch 511/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6123 - accuracy: 0.6734 - val_loss: 0.7224 - val_accuracy: 0.5481\n",
      "Epoch 512/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6031 - accuracy: 0.6785 - val_loss: 0.7434 - val_accuracy: 0.5385\n",
      "Epoch 513/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5941 - accuracy: 0.6801 - val_loss: 0.7771 - val_accuracy: 0.5192\n",
      "Epoch 514/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5776 - accuracy: 0.6919 - val_loss: 0.7507 - val_accuracy: 0.5577\n",
      "Epoch 515/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6162 - accuracy: 0.6431 - val_loss: 0.7914 - val_accuracy: 0.5000\n",
      "Epoch 516/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6098 - accuracy: 0.6582 - val_loss: 0.8969 - val_accuracy: 0.4904\n",
      "Epoch 517/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6116 - accuracy: 0.6448 - val_loss: 0.7364 - val_accuracy: 0.4904\n",
      "Epoch 518/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6102 - accuracy: 0.6801 - val_loss: 0.8182 - val_accuracy: 0.5192\n",
      "Epoch 519/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6373 - accuracy: 0.6279 - val_loss: 0.7572 - val_accuracy: 0.4712\n",
      "Epoch 520/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6362 - accuracy: 0.6178 - val_loss: 0.7399 - val_accuracy: 0.5385\n",
      "Epoch 521/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6236 - accuracy: 0.6717 - val_loss: 0.7602 - val_accuracy: 0.5288\n",
      "Epoch 522/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6235 - accuracy: 0.6465 - val_loss: 0.8459 - val_accuracy: 0.5096\n",
      "Epoch 523/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6135 - accuracy: 0.6599 - val_loss: 0.8005 - val_accuracy: 0.4904\n",
      "Epoch 524/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6043 - accuracy: 0.6582 - val_loss: 0.8024 - val_accuracy: 0.5000\n",
      "Epoch 525/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6319 - accuracy: 0.6448 - val_loss: 0.7779 - val_accuracy: 0.4712\n",
      "Epoch 526/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6251 - accuracy: 0.6448 - val_loss: 0.8099 - val_accuracy: 0.4808\n",
      "Epoch 527/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6365 - accuracy: 0.6414 - val_loss: 0.7789 - val_accuracy: 0.4327\n",
      "Epoch 528/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6321 - accuracy: 0.6061 - val_loss: 0.7842 - val_accuracy: 0.5288\n",
      "Epoch 529/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6211 - accuracy: 0.6549 - val_loss: 0.8263 - val_accuracy: 0.4904\n",
      "Epoch 530/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6333 - accuracy: 0.6465 - val_loss: 0.7429 - val_accuracy: 0.5481\n",
      "Epoch 531/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6095 - accuracy: 0.6785 - val_loss: 0.8244 - val_accuracy: 0.4615\n",
      "Epoch 532/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6174 - accuracy: 0.6549 - val_loss: 0.7486 - val_accuracy: 0.5000\n",
      "Epoch 533/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6061 - accuracy: 0.6717 - val_loss: 0.7454 - val_accuracy: 0.5000\n",
      "Epoch 534/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5950 - accuracy: 0.6919 - val_loss: 0.7889 - val_accuracy: 0.5096\n",
      "Epoch 535/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6063 - accuracy: 0.6717 - val_loss: 0.7700 - val_accuracy: 0.5096\n",
      "Epoch 536/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6111 - accuracy: 0.6431 - val_loss: 0.7288 - val_accuracy: 0.5577\n",
      "Epoch 537/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6175 - accuracy: 0.6448 - val_loss: 0.7633 - val_accuracy: 0.4712\n",
      "Epoch 538/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6083 - accuracy: 0.6633 - val_loss: 0.8157 - val_accuracy: 0.5288\n",
      "Epoch 539/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6157 - accuracy: 0.6448 - val_loss: 0.7373 - val_accuracy: 0.5481\n",
      "Epoch 540/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6301 - accuracy: 0.6481 - val_loss: 0.7884 - val_accuracy: 0.4808\n",
      "Epoch 541/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5938 - accuracy: 0.6869 - val_loss: 0.7393 - val_accuracy: 0.5000\n",
      "Epoch 542/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6097 - accuracy: 0.6650 - val_loss: 0.7822 - val_accuracy: 0.5385\n",
      "Epoch 543/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6029 - accuracy: 0.6616 - val_loss: 0.7437 - val_accuracy: 0.5096\n",
      "Epoch 544/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5981 - accuracy: 0.6717 - val_loss: 0.7554 - val_accuracy: 0.5481\n",
      "Epoch 545/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5977 - accuracy: 0.6515 - val_loss: 0.7602 - val_accuracy: 0.5096\n",
      "Epoch 546/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5899 - accuracy: 0.6852 - val_loss: 0.7352 - val_accuracy: 0.5096\n",
      "Epoch 547/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6080 - accuracy: 0.6667 - val_loss: 0.7842 - val_accuracy: 0.5192\n",
      "Epoch 548/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6141 - accuracy: 0.6549 - val_loss: 0.7887 - val_accuracy: 0.4904\n",
      "Epoch 549/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5924 - accuracy: 0.6717 - val_loss: 0.7654 - val_accuracy: 0.5481\n",
      "Epoch 550/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6383 - accuracy: 0.6734 - val_loss: 0.7607 - val_accuracy: 0.5096\n",
      "Epoch 551/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5960 - accuracy: 0.6751 - val_loss: 0.7319 - val_accuracy: 0.5385\n",
      "Epoch 552/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5839 - accuracy: 0.6751 - val_loss: 0.7919 - val_accuracy: 0.5192\n",
      "Epoch 553/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5869 - accuracy: 0.7003 - val_loss: 0.7677 - val_accuracy: 0.5000\n",
      "Epoch 554/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6030 - accuracy: 0.6532 - val_loss: 0.7369 - val_accuracy: 0.5577\n",
      "Epoch 555/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5865 - accuracy: 0.6414 - val_loss: 0.8095 - val_accuracy: 0.5000\n",
      "Epoch 556/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6159 - accuracy: 0.6616 - val_loss: 0.7498 - val_accuracy: 0.5096\n",
      "Epoch 557/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6062 - accuracy: 0.6616 - val_loss: 0.7610 - val_accuracy: 0.4904\n",
      "Epoch 558/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5824 - accuracy: 0.6818 - val_loss: 0.7836 - val_accuracy: 0.4904\n",
      "Epoch 559/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6064 - accuracy: 0.6633 - val_loss: 0.7952 - val_accuracy: 0.4519\n",
      "Epoch 560/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6602 - accuracy: 0.6263 - val_loss: 0.7710 - val_accuracy: 0.5192\n",
      "Epoch 561/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6181 - accuracy: 0.6498 - val_loss: 0.8063 - val_accuracy: 0.5000\n",
      "Epoch 562/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6215 - accuracy: 0.6515 - val_loss: 0.7684 - val_accuracy: 0.4712\n",
      "Epoch 563/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6071 - accuracy: 0.6936 - val_loss: 0.7586 - val_accuracy: 0.5288\n",
      "Epoch 564/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5824 - accuracy: 0.6700 - val_loss: 0.7579 - val_accuracy: 0.5096\n",
      "Epoch 565/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5837 - accuracy: 0.6633 - val_loss: 0.7490 - val_accuracy: 0.5577\n",
      "Epoch 566/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6182 - accuracy: 0.6599 - val_loss: 0.8130 - val_accuracy: 0.4904\n",
      "Epoch 567/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6140 - accuracy: 0.6734 - val_loss: 0.7489 - val_accuracy: 0.5000\n",
      "Epoch 568/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5975 - accuracy: 0.6549 - val_loss: 0.7976 - val_accuracy: 0.4904\n",
      "Epoch 569/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5925 - accuracy: 0.6801 - val_loss: 0.7920 - val_accuracy: 0.5192\n",
      "Epoch 570/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5946 - accuracy: 0.6869 - val_loss: 0.7636 - val_accuracy: 0.5000\n",
      "Epoch 571/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5856 - accuracy: 0.6751 - val_loss: 0.7818 - val_accuracy: 0.5192\n",
      "Epoch 572/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5906 - accuracy: 0.6599 - val_loss: 0.7394 - val_accuracy: 0.5000\n",
      "Epoch 573/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5856 - accuracy: 0.6818 - val_loss: 0.7506 - val_accuracy: 0.5577\n",
      "Epoch 574/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5971 - accuracy: 0.6751 - val_loss: 0.7518 - val_accuracy: 0.5288\n",
      "Epoch 575/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6283 - accuracy: 0.6330 - val_loss: 0.7285 - val_accuracy: 0.5192\n",
      "Epoch 576/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6431 - accuracy: 0.6162 - val_loss: 0.7458 - val_accuracy: 0.4808\n",
      "Epoch 577/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6392 - accuracy: 0.6431 - val_loss: 0.7968 - val_accuracy: 0.5673\n",
      "Epoch 578/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6312 - accuracy: 0.6532 - val_loss: 0.7552 - val_accuracy: 0.5577\n",
      "Epoch 579/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5992 - accuracy: 0.6835 - val_loss: 0.7308 - val_accuracy: 0.5288\n",
      "Epoch 580/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5937 - accuracy: 0.6734 - val_loss: 0.8844 - val_accuracy: 0.4808\n",
      "Epoch 581/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5979 - accuracy: 0.6886 - val_loss: 0.7963 - val_accuracy: 0.4615\n",
      "Epoch 582/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6444 - accuracy: 0.6397 - val_loss: 0.8767 - val_accuracy: 0.4712\n",
      "Epoch 583/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6149 - accuracy: 0.6667 - val_loss: 0.7781 - val_accuracy: 0.4712\n",
      "Epoch 584/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6195 - accuracy: 0.6515 - val_loss: 0.8354 - val_accuracy: 0.4904\n",
      "Epoch 585/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6157 - accuracy: 0.6498 - val_loss: 0.8898 - val_accuracy: 0.4808\n",
      "Epoch 586/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6024 - accuracy: 0.6919 - val_loss: 0.7639 - val_accuracy: 0.5192\n",
      "Epoch 587/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6140 - accuracy: 0.6667 - val_loss: 0.8121 - val_accuracy: 0.4615\n",
      "Epoch 588/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6469 - accuracy: 0.6178 - val_loss: 0.8035 - val_accuracy: 0.4712\n",
      "Epoch 589/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6309 - accuracy: 0.6532 - val_loss: 0.7945 - val_accuracy: 0.5096\n",
      "Epoch 590/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6365 - accuracy: 0.6178 - val_loss: 0.8247 - val_accuracy: 0.5000\n",
      "Epoch 591/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6608 - accuracy: 0.6465 - val_loss: 0.7928 - val_accuracy: 0.5000\n",
      "Epoch 592/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6658 - accuracy: 0.5993 - val_loss: 0.7589 - val_accuracy: 0.4808\n",
      "Epoch 593/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6697 - accuracy: 0.5960 - val_loss: 0.7436 - val_accuracy: 0.5000\n",
      "Epoch 594/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6550 - accuracy: 0.6044 - val_loss: 0.8033 - val_accuracy: 0.4904\n",
      "Epoch 595/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6352 - accuracy: 0.6229 - val_loss: 0.8078 - val_accuracy: 0.5096\n",
      "Epoch 596/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6603 - accuracy: 0.6313 - val_loss: 0.7910 - val_accuracy: 0.4519\n",
      "Epoch 597/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6103 - accuracy: 0.6650 - val_loss: 0.7498 - val_accuracy: 0.5000\n",
      "Epoch 598/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6067 - accuracy: 0.6448 - val_loss: 0.8051 - val_accuracy: 0.5000\n",
      "Epoch 599/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6262 - accuracy: 0.6263 - val_loss: 0.7808 - val_accuracy: 0.5577\n",
      "Epoch 600/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5848 - accuracy: 0.6785 - val_loss: 0.8333 - val_accuracy: 0.5096\n",
      "Epoch 601/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5629 - accuracy: 0.6869 - val_loss: 0.7591 - val_accuracy: 0.5096\n",
      "Epoch 602/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5945 - accuracy: 0.6549 - val_loss: 0.7486 - val_accuracy: 0.5288\n",
      "Epoch 603/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6088 - accuracy: 0.6549 - val_loss: 0.7359 - val_accuracy: 0.5385\n",
      "Epoch 604/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5791 - accuracy: 0.6936 - val_loss: 0.7521 - val_accuracy: 0.4904\n",
      "Epoch 605/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6013 - accuracy: 0.6801 - val_loss: 0.7612 - val_accuracy: 0.5385\n",
      "Epoch 606/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5918 - accuracy: 0.6448 - val_loss: 0.8423 - val_accuracy: 0.4808\n",
      "Epoch 607/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5999 - accuracy: 0.6616 - val_loss: 0.7663 - val_accuracy: 0.5000\n",
      "Epoch 608/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5800 - accuracy: 0.6633 - val_loss: 0.7702 - val_accuracy: 0.5096\n",
      "Epoch 609/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5902 - accuracy: 0.6801 - val_loss: 0.7461 - val_accuracy: 0.5385\n",
      "Epoch 610/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6434 - accuracy: 0.6515 - val_loss: 0.8388 - val_accuracy: 0.4904\n",
      "Epoch 611/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6280 - accuracy: 0.6465 - val_loss: 0.7838 - val_accuracy: 0.4808\n",
      "Epoch 612/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5737 - accuracy: 0.6919 - val_loss: 0.7765 - val_accuracy: 0.5288\n",
      "Epoch 613/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5756 - accuracy: 0.6902 - val_loss: 0.7385 - val_accuracy: 0.5385\n",
      "Epoch 614/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5778 - accuracy: 0.6768 - val_loss: 0.7312 - val_accuracy: 0.5096\n",
      "Epoch 615/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5548 - accuracy: 0.7037 - val_loss: 0.7280 - val_accuracy: 0.5288\n",
      "Epoch 616/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5913 - accuracy: 0.6582 - val_loss: 0.7659 - val_accuracy: 0.5385\n",
      "Epoch 617/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5854 - accuracy: 0.6801 - val_loss: 0.7250 - val_accuracy: 0.5577\n",
      "Epoch 618/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5945 - accuracy: 0.6801 - val_loss: 0.7228 - val_accuracy: 0.5481\n",
      "Epoch 619/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5840 - accuracy: 0.6801 - val_loss: 0.7227 - val_accuracy: 0.5288\n",
      "Epoch 620/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5581 - accuracy: 0.7121 - val_loss: 0.7178 - val_accuracy: 0.5577\n",
      "Epoch 621/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5903 - accuracy: 0.6582 - val_loss: 0.8043 - val_accuracy: 0.5192\n",
      "Epoch 622/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5973 - accuracy: 0.6734 - val_loss: 0.8256 - val_accuracy: 0.5000\n",
      "Epoch 623/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5989 - accuracy: 0.6684 - val_loss: 0.7307 - val_accuracy: 0.5385\n",
      "Epoch 624/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5690 - accuracy: 0.7020 - val_loss: 0.7787 - val_accuracy: 0.4808\n",
      "Epoch 625/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5916 - accuracy: 0.6734 - val_loss: 0.7390 - val_accuracy: 0.5288\n",
      "Epoch 626/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5936 - accuracy: 0.6734 - val_loss: 0.7444 - val_accuracy: 0.5673\n",
      "Epoch 627/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5816 - accuracy: 0.6970 - val_loss: 0.7432 - val_accuracy: 0.4904\n",
      "Epoch 628/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6048 - accuracy: 0.6717 - val_loss: 0.8665 - val_accuracy: 0.4808\n",
      "Epoch 629/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5913 - accuracy: 0.6785 - val_loss: 0.7307 - val_accuracy: 0.4904\n",
      "Epoch 630/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5755 - accuracy: 0.6835 - val_loss: 0.7461 - val_accuracy: 0.4808\n",
      "Epoch 631/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5929 - accuracy: 0.6582 - val_loss: 0.7523 - val_accuracy: 0.5481\n",
      "Epoch 632/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5919 - accuracy: 0.6835 - val_loss: 0.7383 - val_accuracy: 0.5385\n",
      "Epoch 633/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6008 - accuracy: 0.6936 - val_loss: 0.7922 - val_accuracy: 0.5288\n",
      "Epoch 634/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5846 - accuracy: 0.6667 - val_loss: 0.7384 - val_accuracy: 0.5192\n",
      "Epoch 635/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5898 - accuracy: 0.6700 - val_loss: 0.8201 - val_accuracy: 0.5000\n",
      "Epoch 636/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6016 - accuracy: 0.6717 - val_loss: 0.7861 - val_accuracy: 0.5192\n",
      "Epoch 637/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5922 - accuracy: 0.6650 - val_loss: 0.7512 - val_accuracy: 0.5385\n",
      "Epoch 638/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6013 - accuracy: 0.6684 - val_loss: 0.7956 - val_accuracy: 0.5481\n",
      "Epoch 639/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5772 - accuracy: 0.6886 - val_loss: 0.7322 - val_accuracy: 0.5192\n",
      "Epoch 640/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5877 - accuracy: 0.6734 - val_loss: 0.7280 - val_accuracy: 0.5288\n",
      "Epoch 641/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5791 - accuracy: 0.6936 - val_loss: 0.7849 - val_accuracy: 0.5192\n",
      "Epoch 642/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5768 - accuracy: 0.6835 - val_loss: 0.7689 - val_accuracy: 0.5192\n",
      "Epoch 643/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5857 - accuracy: 0.6852 - val_loss: 0.7660 - val_accuracy: 0.5385\n",
      "Epoch 644/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5924 - accuracy: 0.6549 - val_loss: 0.7760 - val_accuracy: 0.5288\n",
      "Epoch 645/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6047 - accuracy: 0.6414 - val_loss: 0.7761 - val_accuracy: 0.5192\n",
      "Epoch 646/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5943 - accuracy: 0.6667 - val_loss: 0.7339 - val_accuracy: 0.5096\n",
      "Epoch 647/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5793 - accuracy: 0.6835 - val_loss: 0.8972 - val_accuracy: 0.4904\n",
      "Epoch 648/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6046 - accuracy: 0.6582 - val_loss: 0.7532 - val_accuracy: 0.5000\n",
      "Epoch 649/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5915 - accuracy: 0.6953 - val_loss: 0.8027 - val_accuracy: 0.4712\n",
      "Epoch 650/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6336 - accuracy: 0.6448 - val_loss: 0.7191 - val_accuracy: 0.5673\n",
      "Epoch 651/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6292 - accuracy: 0.6700 - val_loss: 0.8178 - val_accuracy: 0.5096\n",
      "Epoch 652/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6230 - accuracy: 0.6397 - val_loss: 0.7119 - val_accuracy: 0.6058\n",
      "Epoch 653/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6366 - accuracy: 0.6431 - val_loss: 0.7232 - val_accuracy: 0.6058\n",
      "Epoch 654/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6149 - accuracy: 0.6650 - val_loss: 0.7253 - val_accuracy: 0.5673\n",
      "Epoch 655/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6163 - accuracy: 0.6549 - val_loss: 0.7084 - val_accuracy: 0.5962\n",
      "Epoch 656/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6355 - accuracy: 0.6364 - val_loss: 0.6940 - val_accuracy: 0.6250\n",
      "Epoch 657/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6608 - accuracy: 0.6128 - val_loss: 0.7233 - val_accuracy: 0.4808\n",
      "Epoch 658/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6534 - accuracy: 0.6212 - val_loss: 0.7051 - val_accuracy: 0.5962\n",
      "Epoch 659/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6546 - accuracy: 0.6111 - val_loss: 0.7047 - val_accuracy: 0.5865\n",
      "Epoch 660/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6498 - accuracy: 0.6212 - val_loss: 0.7173 - val_accuracy: 0.6250\n",
      "Epoch 661/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6464 - accuracy: 0.6330 - val_loss: 0.7150 - val_accuracy: 0.6250\n",
      "Epoch 662/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6565 - accuracy: 0.5875 - val_loss: 0.7369 - val_accuracy: 0.4423\n",
      "Epoch 663/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6393 - accuracy: 0.6313 - val_loss: 0.7267 - val_accuracy: 0.5192\n",
      "Epoch 664/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6428 - accuracy: 0.6313 - val_loss: 0.7434 - val_accuracy: 0.5769\n",
      "Epoch 665/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5973 - accuracy: 0.6700 - val_loss: 0.7434 - val_accuracy: 0.5288\n",
      "Epoch 666/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6314 - accuracy: 0.6448 - val_loss: 0.7534 - val_accuracy: 0.5096\n",
      "Epoch 667/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6103 - accuracy: 0.6498 - val_loss: 0.7973 - val_accuracy: 0.4712\n",
      "Epoch 668/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6448 - accuracy: 0.6162 - val_loss: 0.7230 - val_accuracy: 0.5385\n",
      "Epoch 669/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6255 - accuracy: 0.6582 - val_loss: 0.7523 - val_accuracy: 0.4712\n",
      "Epoch 670/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6394 - accuracy: 0.6330 - val_loss: 0.7365 - val_accuracy: 0.5481\n",
      "Epoch 671/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6092 - accuracy: 0.6498 - val_loss: 0.8408 - val_accuracy: 0.4519\n",
      "Epoch 672/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6013 - accuracy: 0.6852 - val_loss: 0.7614 - val_accuracy: 0.5096\n",
      "Epoch 673/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5998 - accuracy: 0.6633 - val_loss: 0.8366 - val_accuracy: 0.4423\n",
      "Epoch 674/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6222 - accuracy: 0.6549 - val_loss: 0.7328 - val_accuracy: 0.5192\n",
      "Epoch 675/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6301 - accuracy: 0.6448 - val_loss: 0.7424 - val_accuracy: 0.5481\n",
      "Epoch 676/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6325 - accuracy: 0.6582 - val_loss: 0.7982 - val_accuracy: 0.5481\n",
      "Epoch 677/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6090 - accuracy: 0.6532 - val_loss: 0.7985 - val_accuracy: 0.4808\n",
      "Epoch 678/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6169 - accuracy: 0.6465 - val_loss: 0.8150 - val_accuracy: 0.4519\n",
      "Epoch 679/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6016 - accuracy: 0.6667 - val_loss: 0.7546 - val_accuracy: 0.5481\n",
      "Epoch 680/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6195 - accuracy: 0.6498 - val_loss: 0.7737 - val_accuracy: 0.4423\n",
      "Epoch 681/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6054 - accuracy: 0.6751 - val_loss: 0.7750 - val_accuracy: 0.5096\n",
      "Epoch 682/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6029 - accuracy: 0.6751 - val_loss: 0.7711 - val_accuracy: 0.4904\n",
      "Epoch 683/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6204 - accuracy: 0.6431 - val_loss: 0.7614 - val_accuracy: 0.4904\n",
      "Epoch 684/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.5897 - accuracy: 0.6869 - val_loss: 0.8296 - val_accuracy: 0.4712\n",
      "Epoch 685/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6031 - accuracy: 0.6549 - val_loss: 0.7860 - val_accuracy: 0.4808\n",
      "Epoch 686/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5945 - accuracy: 0.6801 - val_loss: 0.7939 - val_accuracy: 0.5481\n",
      "Epoch 687/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6047 - accuracy: 0.6599 - val_loss: 0.7412 - val_accuracy: 0.5192\n",
      "Epoch 688/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6021 - accuracy: 0.6667 - val_loss: 0.7543 - val_accuracy: 0.5192\n",
      "Epoch 689/1000\n",
      "594/594 [==============================] - 3s 4ms/step - loss: 0.6133 - accuracy: 0.6498 - val_loss: 0.7859 - val_accuracy: 0.4615\n",
      "Epoch 690/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5950 - accuracy: 0.6582 - val_loss: 0.7653 - val_accuracy: 0.5481\n",
      "Epoch 691/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5990 - accuracy: 0.6835 - val_loss: 0.8582 - val_accuracy: 0.4712\n",
      "Epoch 692/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5803 - accuracy: 0.6768 - val_loss: 0.7364 - val_accuracy: 0.5288\n",
      "Epoch 693/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5861 - accuracy: 0.6936 - val_loss: 0.8029 - val_accuracy: 0.4808\n",
      "Epoch 694/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5932 - accuracy: 0.6852 - val_loss: 0.7585 - val_accuracy: 0.5481\n",
      "Epoch 695/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6083 - accuracy: 0.6700 - val_loss: 0.7802 - val_accuracy: 0.4904\n",
      "Epoch 696/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5759 - accuracy: 0.6818 - val_loss: 0.7595 - val_accuracy: 0.5385\n",
      "Epoch 697/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5896 - accuracy: 0.6667 - val_loss: 0.8321 - val_accuracy: 0.4808\n",
      "Epoch 698/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5751 - accuracy: 0.6953 - val_loss: 0.8084 - val_accuracy: 0.4904\n",
      "Epoch 699/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5823 - accuracy: 0.6684 - val_loss: 0.7717 - val_accuracy: 0.5577\n",
      "Epoch 700/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5816 - accuracy: 0.6650 - val_loss: 0.7722 - val_accuracy: 0.5096\n",
      "Epoch 701/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5767 - accuracy: 0.6919 - val_loss: 0.9398 - val_accuracy: 0.5000\n",
      "Epoch 702/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6139 - accuracy: 0.6279 - val_loss: 0.7795 - val_accuracy: 0.5192\n",
      "Epoch 703/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5716 - accuracy: 0.6936 - val_loss: 0.7757 - val_accuracy: 0.4615\n",
      "Epoch 704/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5901 - accuracy: 0.6886 - val_loss: 0.7673 - val_accuracy: 0.5000\n",
      "Epoch 705/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5983 - accuracy: 0.6566 - val_loss: 0.7564 - val_accuracy: 0.5481\n",
      "Epoch 706/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6212 - accuracy: 0.6566 - val_loss: 0.7657 - val_accuracy: 0.5577\n",
      "Epoch 707/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6222 - accuracy: 0.6498 - val_loss: 0.7494 - val_accuracy: 0.5000\n",
      "Epoch 708/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6332 - accuracy: 0.6465 - val_loss: 0.7156 - val_accuracy: 0.5769\n",
      "Epoch 709/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6463 - accuracy: 0.6263 - val_loss: 0.7365 - val_accuracy: 0.5962\n",
      "Epoch 710/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6356 - accuracy: 0.6481 - val_loss: 0.7523 - val_accuracy: 0.5000\n",
      "Epoch 711/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6300 - accuracy: 0.6465 - val_loss: 0.7294 - val_accuracy: 0.5481\n",
      "Epoch 712/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6456 - accuracy: 0.6448 - val_loss: 0.7696 - val_accuracy: 0.4519\n",
      "Epoch 713/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6379 - accuracy: 0.6380 - val_loss: 0.7430 - val_accuracy: 0.5000\n",
      "Epoch 714/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6568 - accuracy: 0.6414 - val_loss: 0.7563 - val_accuracy: 0.5769\n",
      "Epoch 715/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6343 - accuracy: 0.6498 - val_loss: 0.7906 - val_accuracy: 0.4327\n",
      "Epoch 716/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6340 - accuracy: 0.6364 - val_loss: 0.7443 - val_accuracy: 0.5000\n",
      "Epoch 717/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6424 - accuracy: 0.6380 - val_loss: 0.7411 - val_accuracy: 0.5577\n",
      "Epoch 718/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6156 - accuracy: 0.6785 - val_loss: 0.7865 - val_accuracy: 0.4615\n",
      "Epoch 719/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5869 - accuracy: 0.6768 - val_loss: 0.7675 - val_accuracy: 0.4904\n",
      "Epoch 720/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5618 - accuracy: 0.7071 - val_loss: 0.8039 - val_accuracy: 0.4904\n",
      "Epoch 721/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6001 - accuracy: 0.6869 - val_loss: 0.7730 - val_accuracy: 0.5000\n",
      "Epoch 722/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5933 - accuracy: 0.6768 - val_loss: 0.7974 - val_accuracy: 0.5288\n",
      "Epoch 723/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5883 - accuracy: 0.6835 - val_loss: 0.7760 - val_accuracy: 0.4615\n",
      "Epoch 724/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5948 - accuracy: 0.6582 - val_loss: 0.7787 - val_accuracy: 0.4808\n",
      "Epoch 725/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5847 - accuracy: 0.6667 - val_loss: 0.8036 - val_accuracy: 0.4808\n",
      "Epoch 726/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6040 - accuracy: 0.6582 - val_loss: 0.8043 - val_accuracy: 0.5192\n",
      "Epoch 727/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5739 - accuracy: 0.6818 - val_loss: 0.7782 - val_accuracy: 0.5481\n",
      "Epoch 728/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5984 - accuracy: 0.6801 - val_loss: 0.8496 - val_accuracy: 0.4615\n",
      "Epoch 729/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6005 - accuracy: 0.6768 - val_loss: 0.9287 - val_accuracy: 0.4712\n",
      "Epoch 730/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5921 - accuracy: 0.6717 - val_loss: 0.7534 - val_accuracy: 0.5481\n",
      "Epoch 731/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5719 - accuracy: 0.6852 - val_loss: 0.7690 - val_accuracy: 0.5096\n",
      "Epoch 732/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6054 - accuracy: 0.6801 - val_loss: 0.7932 - val_accuracy: 0.4712\n",
      "Epoch 733/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6850 - accuracy: 0.6330 - val_loss: 0.7905 - val_accuracy: 0.4423\n",
      "Epoch 734/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6796 - accuracy: 0.6313 - val_loss: 0.8349 - val_accuracy: 0.5577\n",
      "Epoch 735/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6748 - accuracy: 0.6296 - val_loss: 0.7592 - val_accuracy: 0.5192\n",
      "Epoch 736/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6149 - accuracy: 0.6835 - val_loss: 0.7989 - val_accuracy: 0.4712\n",
      "Epoch 737/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6243 - accuracy: 0.6380 - val_loss: 0.7845 - val_accuracy: 0.4904\n",
      "Epoch 738/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6461 - accuracy: 0.6330 - val_loss: 0.7806 - val_accuracy: 0.4712\n",
      "Epoch 739/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6799 - accuracy: 0.6229 - val_loss: 0.7772 - val_accuracy: 0.5385\n",
      "Epoch 740/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6665 - accuracy: 0.6195 - val_loss: 0.7778 - val_accuracy: 0.5288\n",
      "Epoch 741/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6467 - accuracy: 0.6465 - val_loss: 0.7519 - val_accuracy: 0.5288\n",
      "Epoch 742/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6194 - accuracy: 0.6801 - val_loss: 0.7573 - val_accuracy: 0.5481\n",
      "Epoch 743/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6010 - accuracy: 0.6751 - val_loss: 0.7648 - val_accuracy: 0.4904\n",
      "Epoch 744/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5913 - accuracy: 0.6700 - val_loss: 0.7938 - val_accuracy: 0.4904\n",
      "Epoch 745/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6071 - accuracy: 0.6481 - val_loss: 0.7359 - val_accuracy: 0.5385\n",
      "Epoch 746/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5785 - accuracy: 0.6599 - val_loss: 0.7859 - val_accuracy: 0.5192\n",
      "Epoch 747/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5831 - accuracy: 0.6566 - val_loss: 0.7896 - val_accuracy: 0.5096\n",
      "Epoch 748/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5970 - accuracy: 0.6616 - val_loss: 0.7852 - val_accuracy: 0.4904\n",
      "Epoch 749/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5804 - accuracy: 0.6768 - val_loss: 0.7891 - val_accuracy: 0.5192\n",
      "Epoch 750/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5940 - accuracy: 0.6818 - val_loss: 0.7829 - val_accuracy: 0.4808\n",
      "Epoch 751/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5840 - accuracy: 0.6785 - val_loss: 0.7613 - val_accuracy: 0.4808\n",
      "Epoch 752/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6184 - accuracy: 0.6414 - val_loss: 0.7789 - val_accuracy: 0.5769\n",
      "Epoch 753/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6262 - accuracy: 0.6481 - val_loss: 0.7857 - val_accuracy: 0.4712\n",
      "Epoch 754/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5855 - accuracy: 0.6734 - val_loss: 0.8068 - val_accuracy: 0.5096\n",
      "Epoch 755/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6072 - accuracy: 0.6616 - val_loss: 0.7931 - val_accuracy: 0.4904\n",
      "Epoch 756/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5830 - accuracy: 0.6700 - val_loss: 0.7839 - val_accuracy: 0.4904\n",
      "Epoch 757/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5587 - accuracy: 0.6936 - val_loss: 0.7919 - val_accuracy: 0.5000\n",
      "Epoch 758/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5890 - accuracy: 0.6818 - val_loss: 0.7676 - val_accuracy: 0.5288\n",
      "Epoch 759/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6090 - accuracy: 0.6448 - val_loss: 0.7746 - val_accuracy: 0.5000\n",
      "Epoch 760/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6263 - accuracy: 0.6481 - val_loss: 0.7783 - val_accuracy: 0.4615\n",
      "Epoch 761/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6201 - accuracy: 0.6599 - val_loss: 0.7563 - val_accuracy: 0.5481\n",
      "Epoch 762/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6244 - accuracy: 0.6599 - val_loss: 0.8001 - val_accuracy: 0.4712\n",
      "Epoch 763/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5934 - accuracy: 0.6869 - val_loss: 0.8630 - val_accuracy: 0.4712\n",
      "Epoch 764/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6147 - accuracy: 0.6700 - val_loss: 0.7809 - val_accuracy: 0.4712\n",
      "Epoch 765/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6525 - accuracy: 0.6279 - val_loss: 0.8240 - val_accuracy: 0.4615\n",
      "Epoch 766/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6349 - accuracy: 0.6448 - val_loss: 0.7443 - val_accuracy: 0.5481\n",
      "Epoch 767/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6637 - accuracy: 0.5976 - val_loss: 0.7663 - val_accuracy: 0.3750\n",
      "Epoch 768/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6296 - accuracy: 0.6448 - val_loss: 0.7900 - val_accuracy: 0.4038\n",
      "Epoch 769/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6293 - accuracy: 0.6448 - val_loss: 0.7885 - val_accuracy: 0.4231\n",
      "Epoch 770/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6337 - accuracy: 0.6566 - val_loss: 0.7709 - val_accuracy: 0.4231\n",
      "Epoch 771/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6515 - accuracy: 0.6094 - val_loss: 0.7821 - val_accuracy: 0.3846\n",
      "Epoch 772/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6511 - accuracy: 0.5976 - val_loss: 0.7876 - val_accuracy: 0.3942\n",
      "Epoch 773/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6426 - accuracy: 0.6397 - val_loss: 0.7955 - val_accuracy: 0.4808\n",
      "Epoch 774/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6320 - accuracy: 0.6582 - val_loss: 0.8332 - val_accuracy: 0.4231\n",
      "Epoch 775/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6595 - accuracy: 0.6094 - val_loss: 0.7808 - val_accuracy: 0.4135\n",
      "Epoch 776/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6429 - accuracy: 0.6263 - val_loss: 0.8066 - val_accuracy: 0.3750\n",
      "Epoch 777/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6336 - accuracy: 0.6364 - val_loss: 0.7980 - val_accuracy: 0.4712\n",
      "Epoch 778/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6283 - accuracy: 0.6364 - val_loss: 0.7725 - val_accuracy: 0.4038\n",
      "Epoch 779/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6514 - accuracy: 0.6195 - val_loss: 0.7432 - val_accuracy: 0.5769\n",
      "Epoch 780/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6363 - accuracy: 0.6195 - val_loss: 0.7831 - val_accuracy: 0.4423\n",
      "Epoch 781/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6547 - accuracy: 0.6061 - val_loss: 0.7901 - val_accuracy: 0.4519\n",
      "Epoch 782/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6311 - accuracy: 0.6667 - val_loss: 0.8354 - val_accuracy: 0.3654\n",
      "Epoch 783/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6394 - accuracy: 0.6347 - val_loss: 0.8471 - val_accuracy: 0.5577\n",
      "Epoch 784/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6369 - accuracy: 0.6633 - val_loss: 0.8149 - val_accuracy: 0.5192\n",
      "Epoch 785/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6353 - accuracy: 0.6465 - val_loss: 0.8021 - val_accuracy: 0.3558\n",
      "Epoch 786/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6181 - accuracy: 0.6582 - val_loss: 0.7815 - val_accuracy: 0.4808\n",
      "Epoch 787/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6304 - accuracy: 0.6448 - val_loss: 0.7832 - val_accuracy: 0.5096\n",
      "Epoch 788/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6355 - accuracy: 0.6549 - val_loss: 0.8002 - val_accuracy: 0.4712\n",
      "Epoch 789/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6521 - accuracy: 0.6027 - val_loss: 0.7869 - val_accuracy: 0.3846\n",
      "Epoch 790/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6504 - accuracy: 0.6195 - val_loss: 0.7811 - val_accuracy: 0.3942\n",
      "Epoch 791/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6522 - accuracy: 0.5976 - val_loss: 0.7701 - val_accuracy: 0.4808\n",
      "Epoch 792/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6474 - accuracy: 0.6246 - val_loss: 0.8218 - val_accuracy: 0.3942\n",
      "Epoch 793/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6410 - accuracy: 0.6364 - val_loss: 0.8077 - val_accuracy: 0.3942\n",
      "Epoch 794/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6631 - accuracy: 0.6044 - val_loss: 0.7581 - val_accuracy: 0.4231\n",
      "Epoch 795/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6573 - accuracy: 0.5993 - val_loss: 0.7619 - val_accuracy: 0.4135\n",
      "Epoch 796/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6564 - accuracy: 0.5960 - val_loss: 0.7567 - val_accuracy: 0.4808\n",
      "Epoch 797/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6396 - accuracy: 0.6279 - val_loss: 0.7625 - val_accuracy: 0.4038\n",
      "Epoch 798/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6503 - accuracy: 0.6128 - val_loss: 0.7723 - val_accuracy: 0.4904\n",
      "Epoch 799/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6517 - accuracy: 0.6263 - val_loss: 0.7756 - val_accuracy: 0.5288\n",
      "Epoch 800/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6593 - accuracy: 0.5976 - val_loss: 0.8186 - val_accuracy: 0.4423\n",
      "Epoch 801/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6324 - accuracy: 0.6465 - val_loss: 0.7854 - val_accuracy: 0.5096\n",
      "Epoch 802/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6350 - accuracy: 0.6532 - val_loss: 0.8039 - val_accuracy: 0.3654\n",
      "Epoch 803/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6264 - accuracy: 0.6684 - val_loss: 0.7929 - val_accuracy: 0.4327\n",
      "Epoch 804/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6240 - accuracy: 0.6515 - val_loss: 0.8060 - val_accuracy: 0.4135\n",
      "Epoch 805/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6219 - accuracy: 0.6785 - val_loss: 0.8524 - val_accuracy: 0.3750\n",
      "Epoch 806/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6312 - accuracy: 0.6431 - val_loss: 0.7867 - val_accuracy: 0.3846\n",
      "Epoch 807/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6239 - accuracy: 0.6532 - val_loss: 0.8021 - val_accuracy: 0.5385\n",
      "Epoch 808/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6173 - accuracy: 0.6835 - val_loss: 0.7782 - val_accuracy: 0.4231\n",
      "Epoch 809/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6260 - accuracy: 0.6549 - val_loss: 0.7611 - val_accuracy: 0.5673\n",
      "Epoch 810/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6037 - accuracy: 0.6835 - val_loss: 0.8335 - val_accuracy: 0.4423\n",
      "Epoch 811/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6373 - accuracy: 0.6532 - val_loss: 0.7515 - val_accuracy: 0.5385\n",
      "Epoch 812/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6289 - accuracy: 0.6582 - val_loss: 0.7712 - val_accuracy: 0.3942\n",
      "Epoch 813/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6333 - accuracy: 0.6481 - val_loss: 0.7627 - val_accuracy: 0.4808\n",
      "Epoch 814/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6186 - accuracy: 0.6616 - val_loss: 0.8421 - val_accuracy: 0.4423\n",
      "Epoch 815/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5977 - accuracy: 0.6835 - val_loss: 0.7585 - val_accuracy: 0.4808\n",
      "Epoch 816/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6331 - accuracy: 0.6667 - val_loss: 0.7615 - val_accuracy: 0.5000\n",
      "Epoch 817/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6233 - accuracy: 0.6532 - val_loss: 0.7882 - val_accuracy: 0.4231\n",
      "Epoch 818/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6419 - accuracy: 0.6246 - val_loss: 0.7464 - val_accuracy: 0.4904\n",
      "Epoch 819/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6348 - accuracy: 0.6616 - val_loss: 0.7423 - val_accuracy: 0.4423\n",
      "Epoch 820/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6556 - accuracy: 0.6128 - val_loss: 0.7789 - val_accuracy: 0.4135\n",
      "Epoch 821/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6578 - accuracy: 0.5909 - val_loss: 0.7299 - val_accuracy: 0.5769\n",
      "Epoch 822/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6477 - accuracy: 0.6364 - val_loss: 0.7578 - val_accuracy: 0.4423\n",
      "Epoch 823/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6337 - accuracy: 0.6313 - val_loss: 0.7353 - val_accuracy: 0.5481\n",
      "Epoch 824/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6496 - accuracy: 0.6145 - val_loss: 0.7636 - val_accuracy: 0.5577\n",
      "Epoch 825/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6559 - accuracy: 0.6044 - val_loss: 0.7614 - val_accuracy: 0.5385\n",
      "Epoch 826/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6597 - accuracy: 0.6111 - val_loss: 0.7435 - val_accuracy: 0.5288\n",
      "Epoch 827/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6595 - accuracy: 0.5943 - val_loss: 0.7403 - val_accuracy: 0.5962\n",
      "Epoch 828/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6499 - accuracy: 0.5943 - val_loss: 0.7476 - val_accuracy: 0.4038\n",
      "Epoch 829/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6418 - accuracy: 0.6330 - val_loss: 0.7432 - val_accuracy: 0.5288\n",
      "Epoch 830/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6422 - accuracy: 0.6279 - val_loss: 0.7440 - val_accuracy: 0.4135\n",
      "Epoch 831/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6417 - accuracy: 0.6162 - val_loss: 0.7739 - val_accuracy: 0.4615\n",
      "Epoch 832/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6299 - accuracy: 0.6684 - val_loss: 0.7449 - val_accuracy: 0.5288\n",
      "Epoch 833/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6363 - accuracy: 0.6229 - val_loss: 0.7690 - val_accuracy: 0.4712\n",
      "Epoch 834/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6298 - accuracy: 0.6313 - val_loss: 0.7662 - val_accuracy: 0.4808\n",
      "Epoch 835/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6376 - accuracy: 0.6549 - val_loss: 0.8799 - val_accuracy: 0.4135\n",
      "Epoch 836/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6246 - accuracy: 0.6566 - val_loss: 0.8086 - val_accuracy: 0.4519\n",
      "Epoch 837/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6083 - accuracy: 0.6768 - val_loss: 0.7649 - val_accuracy: 0.5096\n",
      "Epoch 838/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6076 - accuracy: 0.6700 - val_loss: 0.8627 - val_accuracy: 0.4615\n",
      "Epoch 839/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6110 - accuracy: 0.6582 - val_loss: 0.9075 - val_accuracy: 0.4519\n",
      "Epoch 840/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6145 - accuracy: 0.6532 - val_loss: 0.8665 - val_accuracy: 0.4423\n",
      "Epoch 841/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6058 - accuracy: 0.6717 - val_loss: 0.8769 - val_accuracy: 0.4423\n",
      "Epoch 842/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5949 - accuracy: 0.6953 - val_loss: 0.7769 - val_accuracy: 0.4904\n",
      "Epoch 843/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6202 - accuracy: 0.6515 - val_loss: 0.7655 - val_accuracy: 0.5481\n",
      "Epoch 844/1000\n",
      "594/594 [==============================] - 3s 6ms/step - loss: 0.6197 - accuracy: 0.6751 - val_loss: 0.7715 - val_accuracy: 0.5000\n",
      "Epoch 845/1000\n",
      "594/594 [==============================] - 3s 6ms/step - loss: 0.6227 - accuracy: 0.6582 - val_loss: 0.8830 - val_accuracy: 0.4615\n",
      "Epoch 846/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6297 - accuracy: 0.6684 - val_loss: 0.7863 - val_accuracy: 0.4519\n",
      "Epoch 847/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6197 - accuracy: 0.6330 - val_loss: 0.7880 - val_accuracy: 0.4904\n",
      "Epoch 848/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6300 - accuracy: 0.6616 - val_loss: 0.7839 - val_accuracy: 0.5192\n",
      "Epoch 849/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6136 - accuracy: 0.6801 - val_loss: 0.8167 - val_accuracy: 0.3846\n",
      "Epoch 850/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6247 - accuracy: 0.6717 - val_loss: 0.8155 - val_accuracy: 0.5481\n",
      "Epoch 851/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6346 - accuracy: 0.6414 - val_loss: 0.7860 - val_accuracy: 0.4615\n",
      "Epoch 852/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6241 - accuracy: 0.6751 - val_loss: 0.8147 - val_accuracy: 0.4231\n",
      "Epoch 853/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6206 - accuracy: 0.6768 - val_loss: 0.7936 - val_accuracy: 0.4615\n",
      "Epoch 854/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6098 - accuracy: 0.6431 - val_loss: 0.8393 - val_accuracy: 0.4615\n",
      "Epoch 855/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5971 - accuracy: 0.6700 - val_loss: 0.8047 - val_accuracy: 0.4712\n",
      "Epoch 856/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6010 - accuracy: 0.6481 - val_loss: 0.7906 - val_accuracy: 0.4904\n",
      "Epoch 857/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6058 - accuracy: 0.6785 - val_loss: 0.8242 - val_accuracy: 0.4423\n",
      "Epoch 858/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6008 - accuracy: 0.6684 - val_loss: 0.7889 - val_accuracy: 0.5288\n",
      "Epoch 859/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6011 - accuracy: 0.6734 - val_loss: 0.8756 - val_accuracy: 0.4423\n",
      "Epoch 860/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5980 - accuracy: 0.6751 - val_loss: 0.8200 - val_accuracy: 0.4712\n",
      "Epoch 861/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6088 - accuracy: 0.6818 - val_loss: 0.8153 - val_accuracy: 0.4808\n",
      "Epoch 862/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5918 - accuracy: 0.6633 - val_loss: 0.7633 - val_accuracy: 0.5288\n",
      "Epoch 863/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6060 - accuracy: 0.6835 - val_loss: 0.7682 - val_accuracy: 0.5192\n",
      "Epoch 864/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5813 - accuracy: 0.6801 - val_loss: 0.8845 - val_accuracy: 0.4615\n",
      "Epoch 865/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6087 - accuracy: 0.6616 - val_loss: 0.7731 - val_accuracy: 0.5000\n",
      "Epoch 866/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6185 - accuracy: 0.6599 - val_loss: 0.7822 - val_accuracy: 0.4904\n",
      "Epoch 867/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6121 - accuracy: 0.6734 - val_loss: 0.7735 - val_accuracy: 0.4519\n",
      "Epoch 868/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6168 - accuracy: 0.6431 - val_loss: 0.7833 - val_accuracy: 0.4808\n",
      "Epoch 869/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6042 - accuracy: 0.6566 - val_loss: 0.7849 - val_accuracy: 0.5577\n",
      "Epoch 870/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6027 - accuracy: 0.6616 - val_loss: 0.7562 - val_accuracy: 0.5096\n",
      "Epoch 871/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6013 - accuracy: 0.6667 - val_loss: 0.7627 - val_accuracy: 0.5385\n",
      "Epoch 872/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5726 - accuracy: 0.6902 - val_loss: 0.8004 - val_accuracy: 0.5865\n",
      "Epoch 873/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5925 - accuracy: 0.6936 - val_loss: 0.8778 - val_accuracy: 0.4712\n",
      "Epoch 874/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5921 - accuracy: 0.6700 - val_loss: 0.9194 - val_accuracy: 0.4615\n",
      "Epoch 875/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6512 - accuracy: 0.6431 - val_loss: 0.8108 - val_accuracy: 0.4615\n",
      "Epoch 876/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6182 - accuracy: 0.6616 - val_loss: 0.7884 - val_accuracy: 0.4808\n",
      "Epoch 877/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6430 - accuracy: 0.6599 - val_loss: 0.7869 - val_accuracy: 0.5000\n",
      "Epoch 878/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6374 - accuracy: 0.6414 - val_loss: 0.9275 - val_accuracy: 0.4615\n",
      "Epoch 879/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6297 - accuracy: 0.6448 - val_loss: 0.7882 - val_accuracy: 0.5192\n",
      "Epoch 880/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6137 - accuracy: 0.6818 - val_loss: 0.8347 - val_accuracy: 0.4808\n",
      "Epoch 881/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6266 - accuracy: 0.6330 - val_loss: 0.7954 - val_accuracy: 0.5192\n",
      "Epoch 882/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6146 - accuracy: 0.6768 - val_loss: 0.8563 - val_accuracy: 0.5769\n",
      "Epoch 883/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5951 - accuracy: 0.6818 - val_loss: 0.8054 - val_accuracy: 0.5192\n",
      "Epoch 884/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5815 - accuracy: 0.6852 - val_loss: 0.7607 - val_accuracy: 0.5769\n",
      "Epoch 885/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5931 - accuracy: 0.6970 - val_loss: 0.8069 - val_accuracy: 0.4808\n",
      "Epoch 886/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6028 - accuracy: 0.6717 - val_loss: 0.8402 - val_accuracy: 0.4615\n",
      "Epoch 887/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6053 - accuracy: 0.6717 - val_loss: 0.7566 - val_accuracy: 0.5192\n",
      "Epoch 888/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6088 - accuracy: 0.6818 - val_loss: 0.7706 - val_accuracy: 0.5288\n",
      "Epoch 889/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6112 - accuracy: 0.6751 - val_loss: 0.7468 - val_accuracy: 0.5865\n",
      "Epoch 890/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6137 - accuracy: 0.6684 - val_loss: 0.7621 - val_accuracy: 0.5481\n",
      "Epoch 891/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6074 - accuracy: 0.6650 - val_loss: 0.7702 - val_accuracy: 0.4231\n",
      "Epoch 892/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6074 - accuracy: 0.6582 - val_loss: 0.8149 - val_accuracy: 0.4327\n",
      "Epoch 893/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6375 - accuracy: 0.6431 - val_loss: 0.7762 - val_accuracy: 0.4231\n",
      "Epoch 894/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6215 - accuracy: 0.6465 - val_loss: 0.7656 - val_accuracy: 0.4615\n",
      "Epoch 895/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6195 - accuracy: 0.6616 - val_loss: 0.7827 - val_accuracy: 0.4038\n",
      "Epoch 896/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6194 - accuracy: 0.6532 - val_loss: 0.7912 - val_accuracy: 0.4135\n",
      "Epoch 897/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6173 - accuracy: 0.6633 - val_loss: 0.7775 - val_accuracy: 0.5192\n",
      "Epoch 898/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6117 - accuracy: 0.6515 - val_loss: 0.7806 - val_accuracy: 0.5096\n",
      "Epoch 899/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6191 - accuracy: 0.6498 - val_loss: 0.7699 - val_accuracy: 0.4808\n",
      "Epoch 900/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6212 - accuracy: 0.6599 - val_loss: 0.7743 - val_accuracy: 0.4423\n",
      "Epoch 901/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6062 - accuracy: 0.6852 - val_loss: 0.7694 - val_accuracy: 0.4038\n",
      "Epoch 902/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6250 - accuracy: 0.6212 - val_loss: 0.7641 - val_accuracy: 0.4038\n",
      "Epoch 903/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6580 - accuracy: 0.5976 - val_loss: 0.7521 - val_accuracy: 0.4423\n",
      "Epoch 904/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6465 - accuracy: 0.6246 - val_loss: 0.7497 - val_accuracy: 0.4423\n",
      "Epoch 905/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6549 - accuracy: 0.5993 - val_loss: 0.7590 - val_accuracy: 0.4135\n",
      "Epoch 906/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6495 - accuracy: 0.6162 - val_loss: 0.7474 - val_accuracy: 0.4327\n",
      "Epoch 907/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6506 - accuracy: 0.6195 - val_loss: 0.7730 - val_accuracy: 0.3654\n",
      "Epoch 908/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6481 - accuracy: 0.6431 - val_loss: 0.8115 - val_accuracy: 0.4327\n",
      "Epoch 909/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6414 - accuracy: 0.6195 - val_loss: 0.7759 - val_accuracy: 0.5769\n",
      "Epoch 910/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6391 - accuracy: 0.6111 - val_loss: 0.8617 - val_accuracy: 0.4423\n",
      "Epoch 911/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6370 - accuracy: 0.6397 - val_loss: 0.7636 - val_accuracy: 0.4038\n",
      "Epoch 912/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6348 - accuracy: 0.6448 - val_loss: 0.7687 - val_accuracy: 0.3942\n",
      "Epoch 913/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6284 - accuracy: 0.6364 - val_loss: 0.7810 - val_accuracy: 0.5000\n",
      "Epoch 914/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6322 - accuracy: 0.6330 - val_loss: 0.7656 - val_accuracy: 0.4808\n",
      "Epoch 915/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6190 - accuracy: 0.6448 - val_loss: 0.8031 - val_accuracy: 0.3846\n",
      "Epoch 916/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6094 - accuracy: 0.6667 - val_loss: 0.7928 - val_accuracy: 0.4519\n",
      "Epoch 917/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6262 - accuracy: 0.6347 - val_loss: 0.7978 - val_accuracy: 0.5288\n",
      "Epoch 918/1000\n",
      "594/594 [==============================] - 3s 6ms/step - loss: 0.6175 - accuracy: 0.6684 - val_loss: 0.7993 - val_accuracy: 0.4135\n",
      "Epoch 919/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6120 - accuracy: 0.6650 - val_loss: 0.7991 - val_accuracy: 0.5577\n",
      "Epoch 920/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6204 - accuracy: 0.6667 - val_loss: 0.7908 - val_accuracy: 0.5192\n",
      "Epoch 921/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6215 - accuracy: 0.6380 - val_loss: 0.7914 - val_accuracy: 0.5481\n",
      "Epoch 922/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6259 - accuracy: 0.6397 - val_loss: 0.7730 - val_accuracy: 0.5096\n",
      "Epoch 923/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6176 - accuracy: 0.6869 - val_loss: 0.7813 - val_accuracy: 0.4038\n",
      "Epoch 924/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6061 - accuracy: 0.6835 - val_loss: 0.8891 - val_accuracy: 0.4135\n",
      "Epoch 925/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5976 - accuracy: 0.6902 - val_loss: 0.8001 - val_accuracy: 0.5192\n",
      "Epoch 926/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6067 - accuracy: 0.6936 - val_loss: 0.7987 - val_accuracy: 0.5288\n",
      "Epoch 927/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.5944 - accuracy: 0.6902 - val_loss: 0.7918 - val_accuracy: 0.4231\n",
      "Epoch 928/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6268 - accuracy: 0.6616 - val_loss: 0.7683 - val_accuracy: 0.4423\n",
      "Epoch 929/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6135 - accuracy: 0.6768 - val_loss: 0.7556 - val_accuracy: 0.5000\n",
      "Epoch 930/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6311 - accuracy: 0.6380 - val_loss: 0.7805 - val_accuracy: 0.4135\n",
      "Epoch 931/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6253 - accuracy: 0.6650 - val_loss: 0.8276 - val_accuracy: 0.5481\n",
      "Epoch 932/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6253 - accuracy: 0.6414 - val_loss: 0.8416 - val_accuracy: 0.4423\n",
      "Epoch 933/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6288 - accuracy: 0.6599 - val_loss: 0.7923 - val_accuracy: 0.5192\n",
      "Epoch 934/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6405 - accuracy: 0.6229 - val_loss: 0.7591 - val_accuracy: 0.4904\n",
      "Epoch 935/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6174 - accuracy: 0.6515 - val_loss: 0.7979 - val_accuracy: 0.3750\n",
      "Epoch 936/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6391 - accuracy: 0.6279 - val_loss: 0.8323 - val_accuracy: 0.4423\n",
      "Epoch 937/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6331 - accuracy: 0.6549 - val_loss: 0.7615 - val_accuracy: 0.4038\n",
      "Epoch 938/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6472 - accuracy: 0.6178 - val_loss: 0.7930 - val_accuracy: 0.4231\n",
      "Epoch 939/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6345 - accuracy: 0.6448 - val_loss: 0.7959 - val_accuracy: 0.5096\n",
      "Epoch 940/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6295 - accuracy: 0.6481 - val_loss: 0.8100 - val_accuracy: 0.3846\n",
      "Epoch 941/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6187 - accuracy: 0.6650 - val_loss: 0.8014 - val_accuracy: 0.4904\n",
      "Epoch 942/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6195 - accuracy: 0.6582 - val_loss: 0.8106 - val_accuracy: 0.4615\n",
      "Epoch 943/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6206 - accuracy: 0.6549 - val_loss: 0.7912 - val_accuracy: 0.4327\n",
      "Epoch 944/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6240 - accuracy: 0.6599 - val_loss: 0.8062 - val_accuracy: 0.5096\n",
      "Epoch 945/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6176 - accuracy: 0.6667 - val_loss: 0.7882 - val_accuracy: 0.4327\n",
      "Epoch 946/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6191 - accuracy: 0.6414 - val_loss: 0.8012 - val_accuracy: 0.4519\n",
      "Epoch 947/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6095 - accuracy: 0.6835 - val_loss: 0.8009 - val_accuracy: 0.4519\n",
      "Epoch 948/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6193 - accuracy: 0.6515 - val_loss: 0.7837 - val_accuracy: 0.4712\n",
      "Epoch 949/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6308 - accuracy: 0.6515 - val_loss: 0.7897 - val_accuracy: 0.4808\n",
      "Epoch 950/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6290 - accuracy: 0.6364 - val_loss: 0.8098 - val_accuracy: 0.4327\n",
      "Epoch 951/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6376 - accuracy: 0.6212 - val_loss: 0.7942 - val_accuracy: 0.3750\n",
      "Epoch 952/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6373 - accuracy: 0.6178 - val_loss: 0.8021 - val_accuracy: 0.4135\n",
      "Epoch 953/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6358 - accuracy: 0.6549 - val_loss: 0.7855 - val_accuracy: 0.4327\n",
      "Epoch 954/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6284 - accuracy: 0.6364 - val_loss: 0.8048 - val_accuracy: 0.4904\n",
      "Epoch 955/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6296 - accuracy: 0.6044 - val_loss: 0.8006 - val_accuracy: 0.4038\n",
      "Epoch 956/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6318 - accuracy: 0.6549 - val_loss: 0.8142 - val_accuracy: 0.3846\n",
      "Epoch 957/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6310 - accuracy: 0.6414 - val_loss: 0.8212 - val_accuracy: 0.4135\n",
      "Epoch 958/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6380 - accuracy: 0.6330 - val_loss: 0.7938 - val_accuracy: 0.5096\n",
      "Epoch 959/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6285 - accuracy: 0.6414 - val_loss: 0.7992 - val_accuracy: 0.4519\n",
      "Epoch 960/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6454 - accuracy: 0.6229 - val_loss: 0.7992 - val_accuracy: 0.3846\n",
      "Epoch 961/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6345 - accuracy: 0.6414 - val_loss: 0.8077 - val_accuracy: 0.4038\n",
      "Epoch 962/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6254 - accuracy: 0.6498 - val_loss: 0.8155 - val_accuracy: 0.4038\n",
      "Epoch 963/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6259 - accuracy: 0.6633 - val_loss: 0.7861 - val_accuracy: 0.4519\n",
      "Epoch 964/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6205 - accuracy: 0.6380 - val_loss: 0.8004 - val_accuracy: 0.4135\n",
      "Epoch 965/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6355 - accuracy: 0.6296 - val_loss: 0.8221 - val_accuracy: 0.5096\n",
      "Epoch 966/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6283 - accuracy: 0.6414 - val_loss: 0.8036 - val_accuracy: 0.4615\n",
      "Epoch 967/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6333 - accuracy: 0.6111 - val_loss: 0.7918 - val_accuracy: 0.4519\n",
      "Epoch 968/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6356 - accuracy: 0.6178 - val_loss: 0.8087 - val_accuracy: 0.4135\n",
      "Epoch 969/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6261 - accuracy: 0.6178 - val_loss: 0.8312 - val_accuracy: 0.5096\n",
      "Epoch 970/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6270 - accuracy: 0.6515 - val_loss: 0.8698 - val_accuracy: 0.5288\n",
      "Epoch 971/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6410 - accuracy: 0.6263 - val_loss: 0.7981 - val_accuracy: 0.4327\n",
      "Epoch 972/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6413 - accuracy: 0.6380 - val_loss: 0.7634 - val_accuracy: 0.4038\n",
      "Epoch 973/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6455 - accuracy: 0.6431 - val_loss: 0.7586 - val_accuracy: 0.4615\n",
      "Epoch 974/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6291 - accuracy: 0.6279 - val_loss: 0.7939 - val_accuracy: 0.4135\n",
      "Epoch 975/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6347 - accuracy: 0.6128 - val_loss: 0.8105 - val_accuracy: 0.5288\n",
      "Epoch 976/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6231 - accuracy: 0.6431 - val_loss: 0.8125 - val_accuracy: 0.5000\n",
      "Epoch 977/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6455 - accuracy: 0.6279 - val_loss: 0.7830 - val_accuracy: 0.3942\n",
      "Epoch 978/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6362 - accuracy: 0.6582 - val_loss: 0.7952 - val_accuracy: 0.4615\n",
      "Epoch 979/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6305 - accuracy: 0.6330 - val_loss: 0.7979 - val_accuracy: 0.4712\n",
      "Epoch 980/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6316 - accuracy: 0.6481 - val_loss: 0.7914 - val_accuracy: 0.4038\n",
      "Epoch 981/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6201 - accuracy: 0.6448 - val_loss: 0.7888 - val_accuracy: 0.4712\n",
      "Epoch 982/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6265 - accuracy: 0.6599 - val_loss: 0.8024 - val_accuracy: 0.5000\n",
      "Epoch 983/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6302 - accuracy: 0.6263 - val_loss: 0.8325 - val_accuracy: 0.3558\n",
      "Epoch 984/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6360 - accuracy: 0.6431 - val_loss: 0.7826 - val_accuracy: 0.4327\n",
      "Epoch 985/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6253 - accuracy: 0.6397 - val_loss: 0.8240 - val_accuracy: 0.4135\n",
      "Epoch 986/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6155 - accuracy: 0.6364 - val_loss: 0.8129 - val_accuracy: 0.4808\n",
      "Epoch 987/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6140 - accuracy: 0.6734 - val_loss: 0.8189 - val_accuracy: 0.4327\n",
      "Epoch 988/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6199 - accuracy: 0.6448 - val_loss: 0.8203 - val_accuracy: 0.5192\n",
      "Epoch 989/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6176 - accuracy: 0.6700 - val_loss: 0.8119 - val_accuracy: 0.4231\n",
      "Epoch 990/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6113 - accuracy: 0.6549 - val_loss: 0.8209 - val_accuracy: 0.4712\n",
      "Epoch 991/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6267 - accuracy: 0.6684 - val_loss: 0.8136 - val_accuracy: 0.4519\n",
      "Epoch 992/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6245 - accuracy: 0.6599 - val_loss: 0.8033 - val_accuracy: 0.4423\n",
      "Epoch 993/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6312 - accuracy: 0.6582 - val_loss: 0.8022 - val_accuracy: 0.4327\n",
      "Epoch 994/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6264 - accuracy: 0.6448 - val_loss: 0.8118 - val_accuracy: 0.4231\n",
      "Epoch 995/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6176 - accuracy: 0.6498 - val_loss: 0.8073 - val_accuracy: 0.4808\n",
      "Epoch 996/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6239 - accuracy: 0.6431 - val_loss: 0.8072 - val_accuracy: 0.4327\n",
      "Epoch 997/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6374 - accuracy: 0.6246 - val_loss: 0.7789 - val_accuracy: 0.3942\n",
      "Epoch 998/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6385 - accuracy: 0.6263 - val_loss: 0.7768 - val_accuracy: 0.4038\n",
      "Epoch 999/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6342 - accuracy: 0.6582 - val_loss: 0.7578 - val_accuracy: 0.4135\n",
      "Epoch 1000/1000\n",
      "594/594 [==============================] - 3s 5ms/step - loss: 0.6360 - accuracy: 0.6431 - val_loss: 0.7312 - val_accuracy: 0.4904\n"
     ]
    }
   ],
   "source": [
    "# NB: The model runs significantly faster with CPU vs with GPU\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=1,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf93e88a",
   "metadata": {
    "id": "bf93e88a"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unfortuanetly the model didn't perform as expected. It didn't converge to the right 'behavior'. \n",
    "The loss over the training set continued to decrease. However we didn't notice any significant\n",
    "decrease in the validation loss. Same thing with the accuracy metrics.\n",
    "\n",
    "- One main reason for this is the lack of computational ressources. We didn't manage to train on more\n",
    "than 1000 data point. This is equivalent to 1000 tweet sets. Each of those sets contains more than 100 tweets.\n",
    "So maybe the model needs more training data to finally deduce the relation between single tweet sentiments\n",
    "and aggregated market sentiments.\n",
    "\n",
    "- Also we did not get rid of spam or tweets that don't bear much information. Our reasoning was that\n",
    "the scoring layer should take care of all of that. If a tweet has only a minimal impact on the overall\n",
    "market, then the model would notice that and only assign a tiny score to that tweet. therefore it\n",
    "wouldn't be necessary to remove the tweet manually from our dataset.\n",
    "\n",
    "- The labels that we collected can also play a role in the results we got.\n",
    "Collecting the true labels relies heavily on many hyperparameters, such as the sizes of the time windows\n",
    "and the price movement lag etc. However, again because of the lack of computing ressources,\n",
    "we didn't manage to do any serious hyperparameter optimization.\n",
    "\n",
    "- Furthermore, we don't finetune the bertweet encoder during the training process.\n",
    "Here the reason are again computational ressources, since a single pass forward over the bertweet model\n",
    "using our dataset takes already a few hours with CPU. Even using the GPUs from google colab, it's only\n",
    "possible to do it in 30 minutes, when using a dataset containing just a 1000 data points. So if we want\n",
    "to finetune the bertweet model, a single epoch will take at least 30 minutes, if we use gpu and restrain\n",
    "ourselves to just 1000 data points.\n",
    "\n",
    "- We haven't found any theory/ results in the literature that support our model. So it remains unclear,\n",
    "whether such a model can converge at all.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cleaning_collab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0622b7f9f43143369869eeb453161535": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0acb15c8dddd40dbb1e20009fd6206b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_72cde91e43434eca9634cd68001d3ef4",
       "IPY_MODEL_a70cfa850b904f25849170d8cb513772",
       "IPY_MODEL_38b7d2561eab4df6873a349a3b76c034"
      ],
      "layout": "IPY_MODEL_ab558a3427ec4c0197d369cf117aed29"
     }
    },
    "0f4890c267054fb78eee0b1c84002319": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a715dabd20d4412a2fa98f737e82ba0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f07cfb0aebf4fc4af683e87716e20df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86c69accd07b4a76ac5eb7d9811fd310",
      "placeholder": "",
      "style": "IPY_MODEL_90d0cd545c364bd3a28dd0e5f72a75b7",
      "value": "Downloading: 100%"
     }
    },
    "24ee118ed5de4fa38a4e611a2b2c79e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb498751e01a4a09b7daa9ed0719b5fa",
      "max": 1078931,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0ae058c993742849daecf388e3c8702",
      "value": 1078931
     }
    },
    "2846b77e882a4527bd23f461a8124114": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b485ca0d09d44e5aaacda69367bd1a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38b7d2561eab4df6873a349a3b76c034": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f380782a498440588959413792ca22da",
      "placeholder": "",
      "style": "IPY_MODEL_0f4890c267054fb78eee0b1c84002319",
      "value": " 705M/705M [00:21&lt;00:00, 33.4MB/s]"
     }
    },
    "3c5cd03826a94215a0dc82b6c3784ec0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ca44c9056954f3cad6f0439c55a34c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b485ca0d09d44e5aaacda69367bd1a0",
      "placeholder": "",
      "style": "IPY_MODEL_579f5c425dcf44d89e55564ef4a9e46f",
      "value": "Downloading: 100%"
     }
    },
    "3f9aed00cb634ab9906d24107eccaaaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3f383497a7f416cb5f499f09db13171",
      "placeholder": "",
      "style": "IPY_MODEL_e81d63e9dff74ba98611bf97b5ec5a19",
      "value": " 558/558 [00:00&lt;00:00, 12.5kB/s]"
     }
    },
    "43603bb6aaea4031929b550532549ea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "579f5c425dcf44d89e55564ef4a9e46f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69e8214909714e0f807c1e412131738f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3ca44c9056954f3cad6f0439c55a34c5",
       "IPY_MODEL_83179fbd17074490bd3c3768310a124e",
       "IPY_MODEL_3f9aed00cb634ab9906d24107eccaaaf"
      ],
      "layout": "IPY_MODEL_c83673ba72d64820a995fe09c1095774"
     }
    },
    "6b604f830c234e01995961f16da94710": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72cde91e43434eca9634cd68001d3ef4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb3333664d124a26983e0b9cb6b6a1b3",
      "placeholder": "",
      "style": "IPY_MODEL_b4fb361427c640f5bf3e12445e10f2e4",
      "value": "Downloading: 100%"
     }
    },
    "731fe13490b646c1baca92e90f0cb02a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f46a93115ce34c4385fa5cf0924c7f51",
      "placeholder": "",
      "style": "IPY_MODEL_1a715dabd20d4412a2fa98f737e82ba0",
      "value": "Downloading: 100%"
     }
    },
    "7ab2843c0f2c45ad831d3a190ab4f1a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7bc912675026452fa4e3ba62fa56fdff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_731fe13490b646c1baca92e90f0cb02a",
       "IPY_MODEL_24ee118ed5de4fa38a4e611a2b2c79e2",
       "IPY_MODEL_ddf67949161c4ebba69ee8d1f72a7420"
      ],
      "layout": "IPY_MODEL_6b604f830c234e01995961f16da94710"
     }
    },
    "83179fbd17074490bd3c3768310a124e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a892d46c51974e4480c5a82e54e01317",
      "max": 558,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7ab2843c0f2c45ad831d3a190ab4f1a8",
      "value": 558
     }
    },
    "86c69accd07b4a76ac5eb7d9811fd310": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90d0cd545c364bd3a28dd0e5f72a75b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a643143978d74764a28e17ff2a7a0e70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f07cfb0aebf4fc4af683e87716e20df",
       "IPY_MODEL_d95ca002c7d04e09bebda6970b6e7d48",
       "IPY_MODEL_e67592c58bc745459206df5c7a81595f"
      ],
      "layout": "IPY_MODEL_cc988eb32e134a7d93e7c79e84fd3568"
     }
    },
    "a70cfa850b904f25849170d8cb513772": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b028a2da80ec4fdb8aaeaefe4cea0954",
      "max": 739523780,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43603bb6aaea4031929b550532549ea3",
      "value": 739523780
     }
    },
    "a892d46c51974e4480c5a82e54e01317": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab558a3427ec4c0197d369cf117aed29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b028a2da80ec4fdb8aaeaefe4cea0954": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4fb361427c640f5bf3e12445e10f2e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb498751e01a4a09b7daa9ed0719b5fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c83673ba72d64820a995fe09c1095774": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca3eb273c3ef4c9d9dfc2d37c2b54873": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cc988eb32e134a7d93e7c79e84fd3568": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd19413554d64a38bf0738fc2939b77b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd52a5d7600c49528aec12e2e3d08707": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0ae058c993742849daecf388e3c8702": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d95ca002c7d04e09bebda6970b6e7d48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2846b77e882a4527bd23f461a8124114",
      "max": 843438,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca3eb273c3ef4c9d9dfc2d37c2b54873",
      "value": 843438
     }
    },
    "ddf67949161c4ebba69ee8d1f72a7420": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd52a5d7600c49528aec12e2e3d08707",
      "placeholder": "",
      "style": "IPY_MODEL_cd19413554d64a38bf0738fc2939b77b",
      "value": " 1.03M/1.03M [00:00&lt;00:00, 2.16MB/s]"
     }
    },
    "e3f383497a7f416cb5f499f09db13171": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e67592c58bc745459206df5c7a81595f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0622b7f9f43143369869eeb453161535",
      "placeholder": "",
      "style": "IPY_MODEL_3c5cd03826a94215a0dc82b6c3784ec0",
      "value": " 824k/824k [00:00&lt;00:00, 920kB/s]"
     }
    },
    "e81d63e9dff74ba98611bf97b5ec5a19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f380782a498440588959413792ca22da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f46a93115ce34c4385fa5cf0924c7f51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb3333664d124a26983e0b9cb6b6a1b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
